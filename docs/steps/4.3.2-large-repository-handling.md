# 4.3.2 Large Repository Handling

## Overview
This step implements strategies for efficiently handling large Git repositories, ensuring that the application remains responsive even when working with repositories containing numerous files, extensive commit history, or complex branch structures. This includes incremental loading, data windowing, lazy evaluation, and intelligent fetching of repository data.

## Dependencies
- Git Operations Interface (1.3.2)
- Startup Time Optimizations (4.3.1)
- Configuration Schema Definition (3.3.2)

## Prerequisites
- Working Git Operations Interface (1.3.2)
- Completed Startup Time Optimizations (4.3.1)
- Completed Configuration Schema Definition (3.3.2)

## Implementation Order
1. Implement incremental loading strategies
2. Create virtual list components
3. Add intelligent Git data fetching
4. Develop status cache system
5. Implement smart diff calculation

## Development Guidelines
- Prioritize responsiveness over comprehensive data loading
- Use windowing and pagination for large data sets
- Implement cancellation for long-running operations
- Consider the user's current context to prioritize relevant data
- Design UIs to handle incomplete or partially loaded data

## Tasks

### 1. Create Test File for Repository Size Analyzer
```typescript
// __tests__/services/repositorySizeAnalyzer.test.ts
import { RepositorySizeAnalyzer } from '../../src/services/repositorySizeAnalyzer';
import { GitOperationsService } from '../../src/services/gitOperations';

// Mock dependencies
jest.mock('../../src/services/gitOperations');

describe('RepositorySizeAnalyzer', () => {
  let analyzer: RepositorySizeAnalyzer;
  let mockGitOps: jest.Mocked<GitOperationsService>;
  
  beforeEach(() => {
    mockGitOps = new GitOperationsService('') as jest.Mocked<GitOperationsService>;
    
    // Mock repository statistics
    mockGitOps.getFileCount.mockResolvedValue(5000);
    mockGitOps.getBranchCount.mockResolvedValue(25);
    mockGitOps.getCommitCount.mockResolvedValue(3000);
    mockGitOps.getRepositorySize.mockResolvedValue(250 * 1024 * 1024); // 250 MB
    
    analyzer = new RepositorySizeAnalyzer(mockGitOps);
  });
  
  test('should analyze repository size', async () => {
    const analysis = await analyzer.analyzeRepository();
    
    expect(analysis.fileCount).toBe(5000);
    expect(analysis.branchCount).toBe(25);
    expect(analysis.commitCount).toBe(3000);
    expect(analysis.repositorySize).toBe(250 * 1024 * 1024);
    expect(analysis.isLarge).toBe(true);
  });
  
  test('should determine if repository is large', async () => {
    // Large repository
    const largeAnalysis = await analyzer.analyzeRepository();
    expect(largeAnalysis.isLarge).toBe(true);
    
    // Small repository
    mockGitOps.getFileCount.mockResolvedValue(50);
    mockGitOps.getBranchCount.mockResolvedValue(3);
    mockGitOps.getCommitCount.mockResolvedValue(100);
    mockGitOps.getRepositorySize.mockResolvedValue(5 * 1024 * 1024); // 5 MB
    
    const smallAnalysis = await analyzer.analyzeRepository();
    expect(smallAnalysis.isLarge).toBe(false);
  });
  
  test('should determine optimization strategies', async () => {
    // Large file count
    mockGitOps.getFileCount.mockResolvedValue(10000);
    mockGitOps.getBranchCount.mockResolvedValue(5);
    mockGitOps.getCommitCount.mockResolvedValue(500);
    mockGitOps.getRepositorySize.mockResolvedValue(50 * 1024 * 1024);
    
    const fileAnalysis = await analyzer.analyzeRepository();
    const strategies = analyzer.determineOptimizationStrategies(fileAnalysis);
    
    expect(strategies).toContain('PAGINATED_STATUS');
    expect(strategies).toContain('INDEXED_FILE_SEARCH');
    
    // Large commit history
    mockGitOps.getFileCount.mockResolvedValue(100);
    mockGitOps.getBranchCount.mockResolvedValue(5);
    mockGitOps.getCommitCount.mockResolvedValue(10000);
    
    const commitAnalysis = await analyzer.analyzeRepository();
    const commitStrategies = analyzer.determineOptimizationStrategies(commitAnalysis);
    
    expect(commitStrategies).toContain('WINDOWED_HISTORY');
    expect(commitStrategies).toContain('LAZY_COMMIT_LOADING');
  });
  
  test('should analyze specific directories', async () => {
    mockGitOps.getDirectoryStats.mockImplementation(async (dir) => {
      if (dir === 'src') {
        return { fileCount: 1000, size: 50 * 1024 * 1024 };
      } else if (dir === 'node_modules') {
        return { fileCount: 30000, size: 150 * 1024 * 1024 };
      }
      return { fileCount: 0, size: 0 };
    });
    
    const dirStats = await analyzer.analyzeDirectories(['src', 'node_modules']);
    
    expect(dirStats).toHaveLength(2);
    expect(dirStats[0].directory).toBe('src');
    expect(dirStats[0].fileCount).toBe(1000);
    expect(dirStats[1].directory).toBe('node_modules');
    expect(dirStats[1].fileCount).toBe(30000);
  });
  
  test('should generate optimization suggestions', async () => {
    // Large repository
    const analysis = await analyzer.analyzeRepository();
    const suggestions = analyzer.generateOptimizationSuggestions(analysis);
    
    expect(suggestions).toHaveLength(4);
    expect(suggestions[0]).toContain('Enable incremental loading');
  });
});
```

### 2. Create Test File for Virtual List Component
```typescript
// __tests__/components/virtualList.test.tsx
import React from 'react';
import { render } from 'ink-testing-library';
import { VirtualList } from '../../src/components/virtualList';

describe('VirtualList', () => {
  const items = Array.from({ length: 1000 }, (_, i) => ({
    key: `item-${i}`,
    value: `Item ${i}`
  }));
  
  test('should render only visible items', () => {
    const renderItem = jest.fn(({ item }) => <span>{item.value}</span>);
    
    const { lastFrame } = render(
      <VirtualList
        items={items}
        renderItem={renderItem}
        height={10}
      />
    );
    
    // Should only render what fits in the viewport (10 items)
    expect(renderItem).toHaveBeenCalledTimes(10);
    expect(lastFrame()).toContain('Item 0');
    expect(lastFrame()).toContain('Item 9');
    expect(lastFrame()).not.toContain('Item 10');
  });
  
  test('should handle scrolling', () => {
    const renderItem = jest.fn(({ item }) => <span>{item.value}</span>);
    
    const { lastFrame, stdin } = render(
      <VirtualList
        items={items}
        renderItem={renderItem}
        height={10}
      />
    );
    
    // Initial render shows first 10 items
    expect(lastFrame()).toContain('Item 0');
    
    // Scroll down
    stdin.write('\u001B[B'); // Down arrow
    
    // Should now show items 1-10
    expect(lastFrame()).toContain('Item 1');
    expect(lastFrame()).toContain('Item 10');
    expect(lastFrame()).not.toContain('Item 0');
    
    // Scroll down multiple lines
    for (let i = 0; i < 5; i++) {
      stdin.write('\u001B[B'); // Down arrow
    }
    
    // Should now show items 6-15
    expect(lastFrame()).toContain('Item 6');
    expect(lastFrame()).toContain('Item 15');
    expect(lastFrame()).not.toContain('Item 5');
  });
  
  test('should handle page up/down navigation', () => {
    const { lastFrame, stdin } = render(
      <VirtualList
        items={items}
        renderItem={({ item }) => <span>{item.value}</span>}
        height={10}
      />
    );
    
    // Initial render shows first 10 items
    expect(lastFrame()).toContain('Item 0');
    
    // Page down (shift + down)
    stdin.write('\u001B[1;2B'); // Shift + Down arrow
    
    // Should now show items 10-19
    expect(lastFrame()).toContain('Item 10');
    expect(lastFrame()).toContain('Item 19');
    expect(lastFrame()).not.toContain('Item 9');
    
    // Page up (shift + up)
    stdin.write('\u001B[1;2A'); // Shift + Up arrow
    
    // Should now show items 0-9 again
    expect(lastFrame()).toContain('Item 0');
    expect(lastFrame()).toContain('Item 9');
    expect(lastFrame()).not.toContain('Item 10');
  });
  
  test('should support dynamic item loading', () => {
    const onItemsNeeded = jest.fn();
    
    const { lastFrame, stdin } = render(
      <VirtualList
        items={items.slice(0, 50)} // Only provide first 50 items
        renderItem={({ item }) => <span>{item.value}</span>}
        height={10}
        totalItems={1000} // But indicate there are 1000 total
        onItemsNeeded={onItemsNeeded}
      />
    );
    
    // Scroll to end of available items
    for (let i = 0; i < 45; i++) {
      stdin.write('\u001B[B'); // Down arrow
    }
    
    // Should trigger onItemsNeeded
    expect(onItemsNeeded).toHaveBeenCalledWith({
      startIndex: expect.any(Number),
      endIndex: expect.any(Number)
    });
  });
  
  test('should render loading indicator when waiting for items', () => {
    const { lastFrame } = render(
      <VirtualList
        items={items.slice(0, 50)}
        renderItem={({ item }) => <span>{item.value}</span>}
        height={10}
        totalItems={1000}
        isLoading={true}
      />
    );
    
    expect(lastFrame()).toContain('Loading...');
  });
  
  test('should handle item selection', () => {
    const onSelect = jest.fn();
    
    const { lastFrame, stdin } = render(
      <VirtualList
        items={items}
        renderItem={({ item, isSelected }) => (
          <span>{isSelected ? '>' : ' '} {item.value}</span>
        )}
        height={10}
        onSelect={onSelect}
      />
    );
    
    // Select first item
    stdin.write('\n');
    
    expect(onSelect).toHaveBeenCalledWith(items[0]);
    
    // Move selection down and select
    stdin.write('\u001B[B'); // Down arrow
    stdin.write('\n');
    
    expect(onSelect).toHaveBeenCalledWith(items[1]);
  });
});
```

### 3. Create Test File for Git Data Windowing Service
```typescript
// __tests__/services/gitDataWindowingService.test.ts
import { GitDataWindowingService } from '../../src/services/gitDataWindowingService';
import { GitOperationsService } from '../../src/services/gitOperations';
import { BackgroundWorker } from '../../src/services/backgroundWorker';

// Mock dependencies
jest.mock('../../src/services/gitOperations');
jest.mock('../../src/services/backgroundWorker');

describe('GitDataWindowingService', () => {
  let windowingService: GitDataWindowingService;
  let mockGitOps: jest.Mocked<GitOperationsService>;
  let mockWorker: jest.Mocked<BackgroundWorker>;
  
  const mockCommits = Array.from({ length: 1000 }, (_, i) => ({
    id: `commit-${i}`,
    message: `Commit message ${i}`,
    author: 'Test Author',
    date: new Date(2022, 0, 1, 0, i).toISOString(),
    stats: { additions: 10, deletions: 5 }
  }));
  
  const mockFiles = Array.from({ length: 500 }, (_, i) => ({
    path: `file-${i}.ts`,
    status: i % 3 === 0 ? 'modified' : i % 3 === 1 ? 'added' : 'deleted'
  }));
  
  beforeEach(() => {
    mockGitOps = new GitOperationsService('') as jest.Mocked<GitOperationsService>;
    mockWorker = new BackgroundWorker() as jest.Mocked<BackgroundWorker>;
    
    mockGitOps.getCommitCount.mockResolvedValue(1000);
    mockGitOps.getCommitRange.mockImplementation(async (start, count) => {
      return mockCommits.slice(start, start + count);
    });
    
    mockGitOps.getFileCount.mockResolvedValue(500);
    mockGitOps.getRepositoryStatus.mockImplementation(async (skip, limit) => {
      return {
        branch: 'main',
        files: mockFiles.slice(skip, skip + limit)
      };
    });
    
    mockWorker.execute.mockImplementation(async (_id, task) => {
      return task();
    });
    
    windowingService = new GitDataWindowingService(mockGitOps, mockWorker);
  });
  
  test('should initialize with repository metrics', async () => {
    await windowingService.initialize();
    
    expect(mockGitOps.getCommitCount).toHaveBeenCalled();
    expect(mockGitOps.getFileCount).toHaveBeenCalled();
  });
  
  test('should fetch commit window', async () => {
    await windowingService.initialize();
    
    const commits = await windowingService.getCommitWindow(50, 20);
    
    expect(commits).toHaveLength(20);
    expect(commits[0].id).toBe('commit-50');
    expect(commits[19].id).toBe('commit-69');
    expect(mockGitOps.getCommitRange).toHaveBeenCalledWith(50, 20);
  });
  
  test('should fetch file window', async () => {
    await windowingService.initialize();
    
    const files = await windowingService.getFileWindow(30, 15);
    
    expect(files).toHaveLength(15);
    expect(files[0].path).toBe('file-30.ts');
    expect(files[14].path).toBe('file-44.ts');
  });
  
  test('should prefetch adjacent windows in background', async () => {
    await windowingService.initialize();
    
    // Get a window and trigger prefetch
    await windowingService.getCommitWindow(50, 20, true);
    
    // Should prefetch previous and next windows
    expect(mockWorker.execute).toHaveBeenCalledWith(
      expect.any(String),
      expect.any(Function)
    );
    
    // Call the background task manually to verify it works
    const prefetchTask = mockWorker.execute.mock.calls[0][1];
    const prefetchedCommits = await prefetchTask();
    
    expect(prefetchedCommits.length).toBeGreaterThan(0);
  });
  
  test('should cache window data', async () => {
    await windowingService.initialize();
    
    // First call should fetch from git
    await windowingService.getCommitWindow(10, 5);
    expect(mockGitOps.getCommitRange).toHaveBeenCalledTimes(1);
    
    // Second call for same window should use cache
    await windowingService.getCommitWindow(10, 5);
    expect(mockGitOps.getCommitRange).toHaveBeenCalledTimes(1);
    
    // Different window should cause new fetch
    await windowingService.getCommitWindow(20, 5);
    expect(mockGitOps.getCommitRange).toHaveBeenCalledTimes(2);
  });
  
  test('should handle window at edges of data range', async () => {
    await windowingService.initialize();
    
    // Request window beyond end of data
    const commits = await windowingService.getCommitWindow(990, 20);
    
    // Should return remaining commits
    expect(commits).toHaveLength(10);
    expect(commits[0].id).toBe('commit-990');
    expect(commits[9].id).toBe('commit-999');
  });
  
  test('should invalidate cache', async () => {
    await windowingService.initialize();
    
    // Fetch data to populate cache
    await windowingService.getCommitWindow(10, 5);
    expect(mockGitOps.getCommitRange).toHaveBeenCalledTimes(1);
    
    // Invalidate cache
    windowingService.invalidateCache();
    
    // Should fetch again
    await windowingService.getCommitWindow(10, 5);
    expect(mockGitOps.getCommitRange).toHaveBeenCalledTimes(2);
  });
  
  test('should merge small windows for efficiency', async () => {
    await windowingService.initialize();
    
    // Fetch very small windows that should be merged
    await windowingService.getCommitWindow(10, 2);
    await windowingService.getCommitWindow(12, 2);
    await windowingService.getCommitWindow(14, 2);
    
    // Should have made a single larger fetch rather than multiple small ones
    expect(mockGitOps.getCommitRange).toHaveBeenCalledTimes(1);
    expect(mockGitOps.getCommitRange).toHaveBeenCalledWith(10, 20); // Merged into one larger window
  });
});
```

### 4. Create Test File for Git Status Cache
```typescript
// __tests__/services/gitStatusCache.test.ts
import { GitStatusCache } from '../../src/services/gitStatusCache';
import { GitOperationsService } from '../../src/services/gitOperations';
import { CacheManager } from '../../src/services/cacheManager';

// Mock dependencies
jest.mock('../../src/services/gitOperations');
jest.mock('../../src/services/cacheManager');

describe('GitStatusCache', () => {
  let statusCache: GitStatusCache;
  let mockGitOps: jest.Mocked<GitOperationsService>;
  let mockCacheManager: jest.Mocked<CacheManager>;
  
  const mockStatus = {
    branch: 'feature/test',
    files: [
      { path: 'file1.ts', status: 'modified' },
      { path: 'file2.ts', status: 'added' }
    ]
  };
  
  beforeEach(() => {
    mockGitOps = new GitOperationsService('') as jest.Mocked<GitOperationsService>;
    mockCacheManager = new CacheManager('') as jest.Mocked<CacheManager>;
    
    mockGitOps.getRepositoryStatus.mockResolvedValue(mockStatus);
    mockGitOps.getFileHash.mockImplementation(async (path) => {
      return `hash-for-${path}`;
    });
    
    mockCacheManager.get.mockResolvedValue(null);
    mockCacheManager.set.mockResolvedValue(undefined);
    
    statusCache = new GitStatusCache(mockGitOps, mockCacheManager);
  });
  
  test('should get status from git when not cached', async () => {
    const status = await statusCache.getStatus();
    
    expect(status).toEqual(mockStatus);
    expect(mockGitOps.getRepositoryStatus).toHaveBeenCalled();
    expect(mockCacheManager.set).toHaveBeenCalled();
  });
  
  test('should get status from cache when available', async () => {
    // Set up cached value
    mockCacheManager.get.mockResolvedValue({
      status: mockStatus,
      timestamp: Date.now(),
      hashMap: {
        'file1.ts': 'hash-for-file1.ts',
        'file2.ts': 'hash-for-file2.ts'
      }
    });
    
    // File hashes haven't changed
    mockGitOps.getFileHash.mockImplementation(async (path) => {
      return path === 'file1.ts' ? 'hash-for-file1.ts' : 'hash-for-file2.ts';
    });
    
    const status = await statusCache.getStatus();
    
    expect(status).toEqual(mockStatus);
    expect(mockGitOps.getRepositoryStatus).not.toHaveBeenCalled();
  });
  
  test('should invalidate cache when file hash changes', async () => {
    // Set up cached value
    mockCacheManager.get.mockResolvedValue({
      status: mockStatus,
      timestamp: Date.now(),
      hashMap: {
        'file1.ts': 'hash-for-file1.ts',
        'file2.ts': 'hash-for-file2.ts'
      }
    });
    
    // One file has changed
    mockGitOps.getFileHash.mockImplementation(async (path) => {
      return path === 'file1.ts' ? 'hash-for-file1.ts' : 'new-hash-for-file2.ts';
    });
    
    const status = await statusCache.getStatus();
    
    expect(status).toEqual(mockStatus);
    expect(mockGitOps.getRepositoryStatus).toHaveBeenCalled();
  });
  
  test('should invalidate cache when TTL expires', async () => {
    // Set up expired cached value
    mockCacheManager.get.mockResolvedValue({
      status: mockStatus,
      timestamp: Date.now() - 1000000, // 1000 seconds ago
      hashMap: {
        'file1.ts': 'hash-for-file1.ts',
        'file2.ts': 'hash-for-file2.ts'
      }
    });
    
    statusCache = new GitStatusCache(mockGitOps, mockCacheManager, 60); // 60 second TTL
    
    const status = await statusCache.getStatus();
    
    expect(status).toEqual(mockStatus);
    expect(mockGitOps.getRepositoryStatus).toHaveBeenCalled();
  });
  
  test('should force refresh when requested', async () => {
    // Set up cached value
    mockCacheManager.get.mockResolvedValue({
      status: mockStatus,
      timestamp: Date.now(),
      hashMap: {
        'file1.ts': 'hash-for-file1.ts',
        'file2.ts': 'hash-for-file2.ts'
      }
    });
    
    const status = await statusCache.getStatus(true);
    
    expect(status).toEqual(mockStatus);
    expect(mockGitOps.getRepositoryStatus).toHaveBeenCalled();
  });
  
  test('should cache by directory', async () => {
    await statusCache.getStatusForDirectory('src');
    
    expect(mockGitOps.getRepositoryStatus).toHaveBeenCalledWith(
      expect.anything(),
      expect.anything(),
      'src'
    );
    expect(mockCacheManager.set).toHaveBeenCalledWith(
      expect.stringContaining('src'),
      expect.anything(),
      expect.anything()
    );
  });
  
  test('should optimize for frequently accessed directories', async () => {
    // Access same directory multiple times
    await statusCache.getStatusForDirectory('src');
    await statusCache.getStatusForDirectory('src');
    await statusCache.getStatusForDirectory('src');
    
    // Should have longer TTL for frequently accessed directories
    expect(mockCacheManager.set).toHaveBeenLastCalledWith(
      expect.any(String),
      expect.any(Object),
      expect.any(Number) // TTL should be increased
    );
  });
});
```

### 5. Create Test File for Smart Diff Calculator
```typescript
// __tests__/services/smartDiffCalculator.test.ts
import { SmartDiffCalculator } from '../../src/services/smartDiffCalculator';
import { GitOperationsService } from '../../src/services/gitOperations';
import { RepositorySizeAnalyzer } from '../../src/services/repositorySizeAnalyzer';

// Mock dependencies
jest.mock('../../src/services/gitOperations');
jest.mock('../../src/services/repositorySizeAnalyzer');

describe('SmartDiffCalculator', () => {
  let diffCalculator: SmartDiffCalculator;
  let mockGitOps: jest.Mocked<GitOperationsService>;
  let mockAnalyzer: jest.Mocked<RepositorySizeAnalyzer>;
  
  const smallDiffMock = {
    files: ['file1.ts', 'file2.ts'],
    changes: [
      {
        path: 'file1.ts',
        hunks: [
          {
            oldStart: 10,
            oldLines: 5,
            newStart: 10,
            newLines: 8,
            lines: ['+new line', ' context', '-old line']
          }
        ]
      },
      {
        path: 'file2.ts',
        hunks: [
          {
            oldStart: 20,
            oldLines: 2,
            newStart: 20,
            newLines: 2,
            lines: [' context', '-old line', '+new line']
          }
        ]
      }
    ],
    stats: { additions: 2, deletions: 2 }
  };
  
  const largeDiffMock = {
    files: Array.from({ length: 100 }, (_, i) => `file${i}.ts`),
    changes: Array.from({ length: 100 }, (_, i) => ({
      path: `file${i}.ts`,
      hunks: Array.from({ length: 10 }, (_, j) => ({
        oldStart: j * 10,
        oldLines: 5,
        newStart: j * 10,
        newLines: 8,
        lines: Array.from({ length: 20 }, (_, k) => 
          k % 3 === 0 ? `+new line ${k}` : k % 3 === 1 ? `-old line ${k}` : ` context ${k}`
        )
      }))
    })),
    stats: { additions: 800, deletions: 500 }
  };
  
  beforeEach(() => {
    mockGitOps = new GitOperationsService('') as jest.Mocked<GitOperationsService>;
    mockAnalyzer = new RepositorySizeAnalyzer(mockGitOps) as jest.Mocked<RepositorySizeAnalyzer>;
    
    // Setup default mock responses
    mockGitOps.getDiff.mockResolvedValue(smallDiffMock);
    mockGitOps.getDiffStats.mockResolvedValue({ additions: 2, deletions: 2 });
    mockGitOps.getDiffForFile.mockImplementation(async (file) => {
      return {
        path: file,
        hunks: smallDiffMock.changes.find(c => c.path === file)?.hunks || []
      };
    });
    
    mockAnalyzer.analyzeRepository.mockResolvedValue({
      fileCount: 100,
      branchCount: 5,
      commitCount: 500,
      repositorySize: 10 * 1024 * 1024,
      isLarge: false
    });
    
    diffCalculator = new SmartDiffCalculator(mockGitOps, mockAnalyzer);
  });
  
  test('should get full diff for small changes', async () => {
    await diffCalculator.initialize();
    
    const diff = await diffCalculator.getDiff();
    
    expect(diff).toEqual(smallDiffMock);
    expect(mockGitOps.getDiff).toHaveBeenCalled();
  });
  
  test('should use optimized strategy for large diffs', async () => {
    // Setup for large repository
    mockAnalyzer.analyzeRepository.mockResolvedValue({
      fileCount: 10000,
      branchCount: 50,
      commitCount: 5000,
      repositorySize: 500 * 1024 * 1024,
      isLarge: true
    });
    
    mockGitOps.getDiff.mockResolvedValue(largeDiffMock);
    mockGitOps.getDiffStats.mockResolvedValue({ additions: 800, deletions: 500 });
    mockGitOps.getStagedFiles.mockResolvedValue(
      largeDiffMock.files.map(f => ({ path: f, status: 'modified' }))
    );
    
    await diffCalculator.initialize();
    
    // Get summary first
    const summary = await diffCalculator.getDiffSummary();
    expect(summary.stats.additions).toBe(800);
    expect(summary.stats.deletions).toBe(500);
    expect(summary.files).toHaveLength(100);
    
    // Should not have loaded full diff yet
    expect(mockGitOps.getDiff).not.toHaveBeenCalled();
    
    // Load diff for one file
    const fileDiff = await diffCalculator.getDiffForFile('file5.ts');
    expect(fileDiff.path).toBe('file5.ts');
    expect(mockGitOps.getDiffForFile).toHaveBeenCalledWith('file5.ts');
  });
  
  test('should use multi-stage loading for large diffs', async () => {
    // Setup for large repository
    mockAnalyzer.analyzeRepository.mockResolvedValue({
      fileCount: 10000,
      branchCount: 50,
      commitCount: 5000,
      repositorySize: 500 * 1024 * 1024,
      isLarge: true
    });
    
    mockGitOps.getDiff.mockResolvedValue(largeDiffMock);
    
    await diffCalculator.initialize();
    
    // Request diff with multi-stage loading
    const diffPromise = diffCalculator.getDiff(true);
    
    // Should emit progress events
    const progressHandler = jest.fn();
    diffCalculator.onProgress(progressHandler);
    
    const diff = await diffPromise;
    
    expect(diff.files).toHaveLength(100);
    expect(progressHandler).toHaveBeenCalled();
  });
  
  test('should support cancellation for large diff operations', async () => {
    // Setup for large repository
    mockAnalyzer.analyzeRepository.mockResolvedValue({
      fileCount: 10000,
      branchCount: 50,
      commitCount: 5000,
      repositorySize: 500 * 1024 * 1024,
      isLarge: true
    });
    
    // Make getDiff hang until cancelled
    let cancelDiff: () => void;
    mockGitOps.getDiff.mockImplementation(() => {
      return new Promise((resolve, reject) => {
        cancelDiff = () => reject(new Error('Operation cancelled'));
      });
    });
    
    await diffCalculator.initialize();
    
    // Start getting diff
    const diffPromise = diffCalculator.getDiff();
    
    // Cancel the operation
    diffCalculator.cancelOperation();
    
    // Simulate cancellation
    cancelDiff();
    
    await expect(diffPromise).rejects.toThrow('Operation cancelled');
  });
  
  test('should prioritize recently modified files', async () => {
    // Setup for large repository
    mockAnalyzer.analyzeRepository.mockResolvedValue({
      fileCount: 10000,
      branchCount: 50,
      commitCount: 5000,
      repositorySize: 500 * 1024 * 1024,
      isLarge: true
    });
    
    // Setup recently modified files
    mockGitOps.getRecentlyModifiedFiles.mockResolvedValue([
      'file1.ts',
      'file2.ts',
      'file3.ts'
    ]);
    
    await diffCalculator.initialize();
    
    // Get diff summary with prioritized files
    await diffCalculator.getDiffSummary(true);
    
    // Should have loaded diffs for prioritized files
    expect(mockGitOps.getDiffForFile).toHaveBeenCalledWith('file1.ts');
    expect(mockGitOps.getDiffForFile).toHaveBeenCalledWith('file2.ts');
    expect(mockGitOps.getDiffForFile).toHaveBeenCalledWith('file3.ts');
  });
});
```

### 6. Implement Repository Size Analyzer
```typescript
// src/services/repositorySizeAnalyzer.ts
import { GitOperationsService } from './gitOperations';

/**
 * Repository size analysis result
 */
export interface RepositorySizeAnalysis {
  fileCount: number;
  branchCount: number;
  commitCount: number;
  repositorySize: number; // in bytes
  isLarge: boolean;
}

/**
 * Directory specific stats
 */
export interface DirectoryAnalysis {
  directory: string;
  fileCount: number;
  size: number; // in bytes
  largestFiles?: { path: string; size: number }[];
}

/**
 * Optimization strategy type
 */
export type OptimizationStrategy = 
  | 'PAGINATED_STATUS'
  | 'WINDOWED_HISTORY'
  | 'LAZY_COMMIT_LOADING'
  | 'INDEXED_FILE_SEARCH'
  | 'FILE_WATCH_ONLY'
  | 'INCREMENTAL_DIFF'
  | 'DIRECTORY_FOCUS';

/**
 * Service for analyzing repository size and determining optimization strategies
 */
export class RepositorySizeAnalyzer {
  // Thresholds for determining if a repository is large
  private readonly FILE_COUNT_THRESHOLD = 5000;
  private readonly BRANCH_COUNT_THRESHOLD = 20;
  private readonly COMMIT_COUNT_THRESHOLD = 2000;
  private readonly REPO_SIZE_THRESHOLD = 100 * 1024 * 1024; // 100 MB
  
  constructor(private gitOps: GitOperationsService) {}
  
  /**
   * Analyze repository size and complexity
   */
  async analyzeRepository(): Promise<RepositorySizeAnalysis> {
    const [fileCount, branchCount, commitCount, repositorySize] = await Promise.all([
      this.gitOps.getFileCount(),
      this.gitOps.getBranchCount(),
      this.gitOps.getCommitCount(),
      this.gitOps.getRepositorySize()
    ]);
    
    const isLarge = this.isLargeRepository({
      fileCount,
      branchCount,
      commitCount,
      repositorySize,
      isLarge: false
    });
    
    return {
      fileCount,
      branchCount,
      commitCount,
      repositorySize,
      isLarge
    };
  }
  
  /**
   * Determine if repository is large based on thresholds
   */
  private isLargeRepository(analysis: RepositorySizeAnalysis): boolean {
    return (
      analysis.fileCount > this.FILE_COUNT_THRESHOLD ||
      analysis.branchCount > this.BRANCH_COUNT_THRESHOLD ||
      analysis.commitCount > this.COMMIT_COUNT_THRESHOLD ||
      analysis.repositorySize > this.REPO_SIZE_THRESHOLD
    );
  }
  
  /**
   * Determine optimization strategies based on repository characteristics
   */
  determineOptimizationStrategies(analysis: RepositorySizeAnalysis): OptimizationStrategy[] {
    const strategies: OptimizationStrategy[] = [];
    
    if (!analysis.isLarge) {
      return strategies;
    }
    
    if (analysis.fileCount > this.FILE_COUNT_THRESHOLD) {
      strategies.push('PAGINATED_STATUS');
      strategies.push('INDEXED_FILE_SEARCH');
      strategies.push('DIRECTORY_FOCUS');
    }
    
    if (analysis.commitCount > this.COMMIT_COUNT_THRESHOLD) {
      strategies.push('WINDOWED_HISTORY');
      strategies.push('LAZY_COMMIT_LOADING');
    }
    
    if (analysis.repositorySize > this.REPO_SIZE_THRESHOLD) {
      strategies.push('FILE_WATCH_ONLY');
      strategies.push('INCREMENTAL_DIFF');
    }
    
    return strategies;
  }
  
  /**
   * Analyze specific directories in the repository
   */
  async analyzeDirectories(directories: string[]): Promise<DirectoryAnalysis[]> {
    const analyses: DirectoryAnalysis[] = [];
    
    for (const dir of directories) {
      const stats = await this.gitOps.getDirectoryStats(dir);
      
      analyses.push({
        directory: dir,
        fileCount: stats.fileCount,
        size: stats.size
      });
    }
    
    return analyses;
  }
  
  /**
   * Generate optimization suggestions based on repository analysis
   */
  generateOptimizationSuggestions(analysis: RepositorySizeAnalysis): string[] {
    if (!analysis.isLarge) {
      return ['No optimizations needed for this repository size.'];
    }
    
    const suggestions: string[] = [];
    
    if (analysis.fileCount > this.FILE_COUNT_THRESHOLD) {
      suggestions.push(
        'Enable incremental loading for repository status to improve performance.',
        'Use directory-focused operations instead of repository-wide operations.'
      );
    }
    
    if (analysis.commitCount > this.COMMIT_COUNT_THRESHOLD) {
      suggestions.push(
        'Use commit history windowing to display and navigate history efficiently.',
        'Consider shallow clones for faster operations if full history is not needed.'
      );
    }
    
    if (analysis.repositorySize > this.REPO_SIZE_THRESHOLD) {
      suggestions.push(
        'Enable smart diff calculation to optimize memory usage.',
        'Consider using git sparse-checkout to focus on specific directories.'
      );
    }
    
    if (analysis.branchCount > this.BRANCH_COUNT_THRESHOLD) {
      suggestions.push(
        'Use branch filtering to focus on relevant branches.',
        'Consider pruning local branches that track deleted remote branches.'
      );
    }
    
    return suggestions;
  }
}
```

### 7. Implement Virtual List Component
```typescript
// src/components/virtualList.tsx
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { Box, Text, useInput } from 'ink';

interface VirtualListProps<T> {
  items: T[];
  renderItem: (props: { item: T; index: number; isSelected: boolean }) => React.ReactNode;
  height: number;
  width?: number;
  totalItems?: number;
  onItemsNeeded?: (range: { startIndex: number; endIndex: number }) => void;
  onSelect?: (item: T) => void;
  isLoading?: boolean;
  loadingMessage?: string;
  emptyMessage?: string;
}

/**
 * Generic virtual list component for efficiently displaying large lists
 */
export function VirtualList<T extends { key: string }>(props: VirtualListProps<T>): React.ReactElement {
  const {
    items,
    renderItem,
    height,
    width,
    totalItems,
    onItemsNeeded,
    onSelect,
    isLoading = false,
    loadingMessage = 'Loading...',
    emptyMessage = 'No items to display'
  } = props;
  
  const [startIndex, setStartIndex] = useState(0);
  const [selectedIndex, setSelectedIndex] = useState(0);
  const previousItemCount = useRef(items.length);
  
  // Calculate visible items
  const visibleItems = items.slice(startIndex, startIndex + height);
  
  // Handler for when more items are needed
  const checkLoadMore = useCallback(() => {
    if (onItemsNeeded && totalItems && startIndex + height >= items.length && items.length < totalItems) {
      onItemsNeeded({
        startIndex: items.length,
        endIndex: Math.min(items.length + height * 2, totalItems)
      });
    }
  }, [startIndex, height, items.length, totalItems, onItemsNeeded]);
  
  // Handle keyboard navigation
  useInput((input, key) => {
    // Down arrow - move selection down
    if (key.downArrow) {
      if (key.shift) {
        // Page down
        const newStartIndex = Math.min(
          startIndex + height,
          totalItems ? totalItems - height : items.length - height
        );
        setStartIndex(Math.max(0, newStartIndex));
        setSelectedIndex(Math.max(0, newStartIndex));
      } else {
        // Move selection down one
        if (selectedIndex < items.length - 1) {
          const newSelectedIndex = selectedIndex + 1;
          setSelectedIndex(newSelectedIndex);
          
          // Scroll if selection goes out of view
          if (newSelectedIndex >= startIndex + height) {
            setStartIndex(startIndex + 1);
            checkLoadMore();
          }
        }
      }
    }
    
    // Up arrow - move selection up
    if (key.upArrow) {
      if (key.shift) {
        // Page up
        const newStartIndex = Math.max(startIndex - height, 0);
        setStartIndex(newStartIndex);
        setSelectedIndex(newStartIndex);
      } else {
        // Move selection up one
        if (selectedIndex > 0) {
          const newSelectedIndex = selectedIndex - 1;
          setSelectedIndex(newSelectedIndex);
          
          // Scroll if selection goes out of view
          if (newSelectedIndex < startIndex) {
            setStartIndex(startIndex - 1);
          }
        }
      }
    }
    
    // Home - go to first item
    if (key.home) {
      setStartIndex(0);
      setSelectedIndex(0);
    }
    
    // End - go to last item
    if (key.end) {
      const maxStartIndex = Math.max(0, items.length - height);
      setStartIndex(maxStartIndex);
      setSelectedIndex(items.length - 1);
      checkLoadMore();
    }
    
    // Enter - select current item
    if (key.return && onSelect && items[selectedIndex]) {
      onSelect(items[selectedIndex]);
    }
  });
  
  // Check if we need to load more items when the component mounts
  useEffect(() => {
    checkLoadMore();
  }, [checkLoadMore]);
  
  // Adjust selection if items are added/removed
  useEffect(() => {
    if (items.length !== previousItemCount.current) {
      previousItemCount.current = items.length;
      
      // Ensure selected index is valid
      if (selectedIndex >= items.length) {
        setSelectedIndex(Math.max(0, items.length - 1));
      }
    }
  }, [items.length, selectedIndex]);
  
  // Render empty state
  if (items.length === 0 && !isLoading) {
    return (
      <Box width={width} height={height} flexDirection="column">
        <Text>{emptyMessage}</Text>
      </Box>
    );
  }
  
  // Render loading state
  if (isLoading && items.length === 0) {
    return (
      <Box width={width} height={height} flexDirection="column">
        <Text>{loadingMessage}</Text>
      </Box>
    );
  }
  
  return (
    <Box width={width} height={height} flexDirection="column">
      {/* Visible items */}
      {visibleItems.map((item, index) => (
        <Box key={item.key}>
          {renderItem({
            item,
            index: startIndex + index,
            isSelected: startIndex + index === selectedIndex
          })}
        </Box>
      ))}
      
      {/* Loading indicator at bottom */}
      {isLoading && items.length > 0 && (
        <Box>
          <Text>{loadingMessage}</Text>
        </Box>
      )}
      
      {/* Scroll position indicator */}
      {totalItems && totalItems > height && (
        <Box position="absolute" right={0} top={0}>
          <Text>
            {Math.floor((startIndex / totalItems) * 100)}%
          </Text>
        </Box>
      )}
    </Box>
  );
}
```

### 8. Implement Git Data Windowing Service
```typescript
// src/services/gitDataWindowingService.ts
import { GitOperationsService } from './gitOperations';
import { BackgroundWorker } from './backgroundWorker';

// Window cache entry
interface WindowCacheEntry<T> {
  startIndex: number;
  endIndex: number;
  data: T[];
  timestamp: number;
}

/**
 * Service for efficiently loading and windowing Git data
 */
export class GitDataWindowingService {
  private commitCount: number = 0;
  private fileCount: number = 0;
  private initialized: boolean = false;
  
  // Cache of loaded windows
  private commitWindows: WindowCacheEntry<any>[] = [];
  private fileWindows: WindowCacheEntry<any>[] = [];
  
  // Minimum window size and cache TTL
  private readonly MIN_WINDOW_SIZE = 20;
  private readonly CACHE_TTL = 30000; // 30 seconds
  
  constructor(
    private gitOps: GitOperationsService,
    private worker: BackgroundWorker
  ) {}
  
  /**
   * Initialize the service with repository metrics
   */
  async initialize(): Promise<void> {
    if (this.initialized) {
      return;
    }
    
    const [commitCount, fileCount] = await Promise.all([
      this.gitOps.getCommitCount(),
      this.gitOps.getFileCount()
    ]);
    
    this.commitCount = commitCount;
    this.fileCount = fileCount;
    this.initialized = true;
  }
  
  /**
   * Get a window of commits
   * @param startIndex Start index in the commit list
   * @param count Number of commits to get
   * @param prefetch Whether to prefetch adjacent windows
   * @returns Array of commits in the window
   */
  async getCommitWindow(
    startIndex: number,
    count: number,
    prefetch: boolean = false
  ): Promise<any[]> {
    await this.ensureInitialized();
    
    // Ensure valid window parameters
    const validatedStartIndex = Math.max(0, startIndex);
    const validatedCount = Math.min(count, this.commitCount - validatedStartIndex);
    
    // Check cache first
    const cachedWindow = this.findCommitWindow(validatedStartIndex, validatedCount);
    if (cachedWindow) {
      const windowStartOffset = validatedStartIndex - cachedWindow.startIndex;
      const windowData = cachedWindow.data.slice(
        windowStartOffset,
        windowStartOffset + validatedCount
      );
      
      if (prefetch) {
        this.prefetchCommitWindows(validatedStartIndex, validatedCount);
      }
      
      return windowData;
    }
    
    // Calculate optimal window size (may fetch more than requested for efficiency)
    const optimalWindowSize = Math.max(
      this.MIN_WINDOW_SIZE,
      validatedCount * 2
    );
    
    // Calculate optimal start index to center requested window within fetched data
    const optimalStartIndex = Math.max(
      0,
      validatedStartIndex - Math.floor((optimalWindowSize - validatedCount) / 2)
    );
    
    // Fetch optimal window
    const optimalEndIndex = Math.min(
      optimalStartIndex + optimalWindowSize,
      this.commitCount
    );
    const actualCount = optimalEndIndex - optimalStartIndex;
    
    const commits = await this.gitOps.getCommitRange(
      optimalStartIndex,
      actualCount
    );
    
    // Store in cache
    this.commitWindows.push({
      startIndex: optimalStartIndex,
      endIndex: optimalStartIndex + commits.length,
      data: commits,
      timestamp: Date.now()
    });
    
    // Clean up old cache entries
    this.cleanupCache();
    
    // If prefetch is requested, fetch adjacent windows in background
    if (prefetch) {
      this.prefetchCommitWindows(validatedStartIndex, validatedCount);
    }
    
    // Return just the requested window
    const windowStartOffset = validatedStartIndex - optimalStartIndex;
    return commits.slice(
      windowStartOffset,
      windowStartOffset + validatedCount
    );
  }
  
  /**
   * Get a window of files
   * @param startIndex Start index in the file list
   * @param count Number of files to get
   * @param prefetch Whether to prefetch adjacent windows
   * @returns Array of files in the window
   */
  async getFileWindow(
    startIndex: number,
    count: number,
    prefetch: boolean = false
  ): Promise<any[]> {
    await this.ensureInitialized();
    
    // Ensure valid window parameters
    const validatedStartIndex = Math.max(0, startIndex);
    const validatedCount = Math.min(count, this.fileCount - validatedStartIndex);
    
    // Check cache first
    const cachedWindow = this.findFileWindow(validatedStartIndex, validatedCount);
    if (cachedWindow) {
      const windowStartOffset = validatedStartIndex - cachedWindow.startIndex;
      const windowData = cachedWindow.data.slice(
        windowStartOffset,
        windowStartOffset + validatedCount
      );
      
      if (prefetch) {
        this.prefetchFileWindows(validatedStartIndex, validatedCount);
      }
      
      return windowData;
    }
    
    // Calculate optimal window size (may fetch more than requested for efficiency)
    const optimalWindowSize = Math.max(
      this.MIN_WINDOW_SIZE,
      validatedCount * 2
    );
    
    // Calculate optimal start index to center requested window within fetched data
    const optimalStartIndex = Math.max(
      0,
      validatedStartIndex - Math.floor((optimalWindowSize - validatedCount) / 2)
    );
    
    // Fetch optimal window
    const optimalEndIndex = Math.min(
      optimalStartIndex + optimalWindowSize,
      this.fileCount
    );
    const actualCount = optimalEndIndex - optimalStartIndex;
    
    const status = await this.gitOps.getRepositoryStatus(
      optimalStartIndex,
      actualCount
    );
    
    // Store in cache
    this.fileWindows.push({
      startIndex: optimalStartIndex,
      endIndex: optimalStartIndex + status.files.length,
      data: status.files,
      timestamp: Date.now()
    });
    
    // Clean up old cache entries
    this.cleanupCache();
    
    // If prefetch is requested, fetch adjacent windows in background
    if (prefetch) {
      this.prefetchFileWindows(validatedStartIndex, validatedCount);
    }
    
    // Return just the requested window
    const windowStartOffset = validatedStartIndex - optimalStartIndex;
    return status.files.slice(
      windowStartOffset,
      windowStartOffset + validatedCount
    );
  }
  
  /**
   * Invalidate the cache
   */
  invalidateCache(): void {
    this.commitWindows = [];
    this.fileWindows = [];
  }
  
  /**
   * Get the total number of commits
   */
  getCommitCount(): number {
    return this.commitCount;
  }
  
  /**
   * Get the total number of files
   */
  getFileCount(): number {
    return this.fileCount;
  }
  
  /**
   * Find a commit window in the cache
   */
  private findCommitWindow(startIndex: number, count: number): WindowCacheEntry<any> | undefined {
    const endIndex = startIndex + count;
    const now = Date.now();
    
    return this.commitWindows.find(window => {
      // Check if window contains the requested range
      const containsRange = startIndex >= window.startIndex && endIndex <= window.endIndex;
      
      // Check if window is still valid
      const isValid = now - window.timestamp < this.CACHE_TTL;
      
      return containsRange && isValid;
    });
  }
  
  /**
   * Find a file window in the cache
   */
  private findFileWindow(startIndex: number, count: number): WindowCacheEntry<any> | undefined {
    const endIndex = startIndex + count;
    const now = Date.now();
    
    return this.fileWindows.find(window => {
      // Check if window contains the requested range
      const containsRange = startIndex >= window.startIndex && endIndex <= window.endIndex;
      
      // Check if window is still valid
      const isValid = now - window.timestamp < this.CACHE_TTL;
      
      return containsRange && isValid;
    });
  }
  
  /**
   * Prefetch commit windows adjacent to the current one
   */
  private prefetchCommitWindows(startIndex: number, count: number): void {
    const windowSize = Math.max(this.MIN_WINDOW_SIZE, count);
    
    // Prefetch previous window
    const prevStartIndex = Math.max(0, startIndex - windowSize);
    if (prevStartIndex < startIndex && !this.findCommitWindow(prevStartIndex, windowSize)) {
      this.worker.execute('prefetch-prev-commits', async () => {
        return this.getCommitWindow(prevStartIndex, windowSize);
      });
    }
    
    // Prefetch next window
    const nextStartIndex = startIndex + count;
    if (nextStartIndex < this.commitCount && !this.findCommitWindow(nextStartIndex, windowSize)) {
      this.worker.execute('prefetch-next-commits', async () => {
        return this.getCommitWindow(nextStartIndex, windowSize);
      });
    }
  }
  
  /**
   * Prefetch file windows adjacent to the current one
   */
  private prefetchFileWindows(startIndex: number, count: number): void {
    const windowSize = Math.max(this.MIN_WINDOW_SIZE, count);
    
    // Prefetch previous window
    const prevStartIndex = Math.max(0, startIndex - windowSize);
    if (prevStartIndex < startIndex && !this.findFileWindow(prevStartIndex, windowSize)) {
      this.worker.execute('prefetch-prev-files', async () => {
        return this.getFileWindow(prevStartIndex, windowSize);
      });
    }
    
    // Prefetch next window
    const nextStartIndex = startIndex + count;
    if (nextStartIndex < this.fileCount && !this.findFileWindow(nextStartIndex, windowSize)) {
      this.worker.execute('prefetch-next-files', async () => {
        return this.getFileWindow(nextStartIndex, windowSize);
      });
    }
  }
  
  /**
   * Clean up old cache entries
   */
  private cleanupCache(): void {
    const now = Date.now();
    
    // Remove expired commit windows
    this.commitWindows = this.commitWindows.filter(
      window => now - window.timestamp < this.CACHE_TTL
    );
    
    // Remove expired file windows
    this.fileWindows = this.fileWindows.filter(
      window => now - window.timestamp < this.CACHE_TTL
    );
    
    // Limit cache size
    if (this.commitWindows.length > 10) {
      this.commitWindows = this.commitWindows
        .sort((a, b) => b.timestamp - a.timestamp)
        .slice(0, 10);
    }
    
    if (this.fileWindows.length > 10) {
      this.fileWindows = this.fileWindows
        .sort((a, b) => b.timestamp - a.timestamp)
        .slice(0, 10);
    }
  }
  
  /**
   * Ensure the service is initialized
   */
  private async ensureInitialized(): Promise<void> {
    if (!this.initialized) {
      await this.initialize();
    }
  }
}
```

### 9. Implement Git Status Cache
```typescript
// src/services/gitStatusCache.ts
import { GitOperationsService } from './gitOperations';
import { CacheManager } from './cacheManager';

interface CachedStatus {
  status: any;
  timestamp: number;
  hashMap: Record<string, string>;
}

/**
 * Cache for Git repository status
 */
export class GitStatusCache {
  // Default TTL is 10 seconds
  constructor(
    private gitOps: GitOperationsService,
    private cacheManager: CacheManager,
    private ttl: number = 10
  ) {}
  
  /**
   * Get repository status, using cache if valid
   * @param forceRefresh Force a refresh of the status
   * @returns Repository status
   */
  async getStatus(forceRefresh: boolean = false): Promise<any> {
    const cacheKey = 'git-status';
    
    if (!forceRefresh) {
      // Try to get from cache
      const cached = await this.cacheManager.get<CachedStatus>(cacheKey);
      
      if (cached) {
        // Check if cache is still valid
        if (await this.isCacheValid(cached)) {
          return cached.status;
        }
      }
    }
    
    // Get current status
    const status = await this.gitOps.getRepositoryStatus();
    
    // Build file hash map for cache validation
    const hashMap: Record<string, string> = {};
    for (const file of status.files) {
      hashMap[file.path] = await this.gitOps.getFileHash(file.path);
    }
    
    // Cache the status
    await this.cacheManager.set(cacheKey, {
      status,
      timestamp: Date.now(),
      hashMap
    }, this.ttl * 1000);
    
    return status;
  }
  
  /**
   * Get status for a specific directory
   * @param directory Directory path
   * @param forceRefresh Force refresh
   * @returns Status for the directory
   */
  async getStatusForDirectory(
    directory: string,
    forceRefresh: boolean = false
  ): Promise<any> {
    const cacheKey = `git-status-${directory}`;
    
    if (!forceRefresh) {
      // Try to get from cache
      const cached = await this.cacheManager.get<CachedStatus>(cacheKey);
      
      if (cached) {
        // Check if cache is still valid
        if (await this.isCacheValid(cached)) {
          return cached.status;
        }
      }
    }
    
    // Get current status for directory
    const status = await this.gitOps.getRepositoryStatus(0, 0, directory);
    
    // Build file hash map for cache validation
    const hashMap: Record<string, string> = {};
    for (const file of status.files) {
      hashMap[file.path] = await this.gitOps.getFileHash(file.path);
    }
    
    // Determine appropriate TTL based on directory access frequency
    let directoryTtl = this.ttl;
    if (await this.isFrequentlyAccessed(directory)) {
      directoryTtl = this.ttl * 2; // Longer TTL for frequently accessed directories
    }
    
    // Cache the status
    await this.cacheManager.set(cacheKey, {
      status,
      timestamp: Date.now(),
      hashMap
    }, directoryTtl * 1000);
    
    return status;
  }
  
  /**
   * Clear the status cache
   */
  async clearCache(): Promise<void> {
    await this.cacheManager.delete('git-status');
    
    // Clear directory-specific caches
    const keys = await this.cacheManager.getAllKeys();
    for (const key of keys) {
      if (key.startsWith('git-status-')) {
        await this.cacheManager.delete(key);
      }
    }
  }
  
  /**
   * Check if cached status is still valid
   */
  private async isCacheValid(cached: CachedStatus): Promise<boolean> {
    // Check TTL
    const age = (Date.now() - cached.timestamp) / 1000;
    if (age > this.ttl) {
      return false;
    }
    
    // Check if any of the files have changed
    for (const [path, hash] of Object.entries(cached.hashMap)) {
      try {
        const currentHash = await this.gitOps.getFileHash(path);
        if (currentHash !== hash) {
          return false;
        }
      } catch (error) {
        // File might have been deleted or renamed
        return false;
      }
    }
    
    return true;
  }
  
  /**
   * Check if a directory is frequently accessed
   */
  private async isFrequentlyAccessed(directory: string): Promise<boolean> {
    // This could be implemented by tracking access counts in a separate cache
    // For now, we'll use a simple heuristic based on common directories
    const frequentDirs = ['src', 'lib', 'app', 'components', 'pages'];
    return frequentDirs.some(dir => directory.includes(dir));
  }
}
```

### 10. Implement Smart Diff Calculator
```typescript
// src/services/smartDiffCalculator.ts
import { GitOperationsService } from './gitOperations';
import { RepositorySizeAnalyzer } from './repositorySizeAnalyzer';
import { EventEmitter } from 'events';

type ProgressCallback = (progress: { loaded: number; total: number }) => void;

/**
 * Service for intelligently calculating diffs in large repositories
 */
export class SmartDiffCalculator extends EventEmitter {
  private isLargeRepo: boolean = false;
  private currentOperation: AbortController | null = null;
  private initialized: boolean = false;
  
  constructor(
    private gitOps: GitOperationsService,
    private repoAnalyzer: RepositorySizeAnalyzer
  ) {
    super();
  }
  
  /**
   * Initialize the calculator
   */
  async initialize(): Promise<void> {
    if (this.initialized) {
      return;
    }
    
    // Analyze repository to determine strategies
    const analysis = await this.repoAnalyzer.analyzeRepository();
    this.isLargeRepo = analysis.isLarge;
    
    this.initialized = true;
  }
  
  /**
   * Get diff summary (files and stats, without full content)
   * @param prioritizeRecent Prioritize recently modified files
   * @returns Diff summary
   */
  async getDiffSummary(prioritizeRecent: boolean = false): Promise<any> {
    await this.ensureInitialized();
    
    // For large repos, get just the stats and files
    if (this.isLargeRepo) {
      const [stats, stagedFiles] = await Promise.all([
        this.gitOps.getDiffStats(),
        this.gitOps.getStagedFiles()
      ]);
      
      const summary = {
        files: stagedFiles.map(f => f.path),
        stats
      };
      
      // If prioritizing recent files, load diffs for recently modified files
      if (prioritizeRecent) {
        const recentFiles = await this.gitOps.getRecentlyModifiedFiles(10);
        
        // Preload diffs for recently modified files
        await Promise.all(
          recentFiles
            .filter(file => stagedFiles.some(f => f.path === file))
            .map(file => this.getDiffForFile(file))
        );
      }
      
      return summary;
    }
    
    // For small repos, get the full diff and extract summary
    const diff = await this.gitOps.getDiff();
    
    return {
      files: diff.files,
      stats: diff.stats
    };
  }
  
  /**
   * Get diff for a specific file
   * @param filePath File path
   * @returns Diff for the file
   */
  async getDiffForFile(filePath: string): Promise<any> {
    await this.ensureInitialized();
    
    return this.gitOps.getDiffForFile(filePath);
  }
  
  /**
   * Get full diff with optimizations for large repositories
   * @param incremental Use incremental loading for large diffs
   * @returns Full diff
   */
  async getDiff(incremental: boolean = false): Promise<any> {
    await this.ensureInitialized();
    
    // For small repos or non-incremental mode, get full diff at once
    if (!this.isLargeRepo || !incremental) {
      return this.gitOps.getDiff();
    }
    
    // For large repos in incremental mode, load diff in stages
    const abortController = new AbortController();
    this.currentOperation = abortController;
    
    try {
      // Get diff summary first
      const summary = await this.getDiffSummary();
      this.emit('progress', { loaded: 0, total: summary.files.length });
      
      // Load diffs for each file incrementally
      const changes: any[] = [];
      let loadedCount = 0;
      
      for (const filePath of summary.files) {
        // Check for cancellation
        if (abortController.signal.aborted) {
          throw new Error('Operation cancelled');
        }
        
        // Load diff for file
        const fileDiff = await this.getDiffForFile(filePath);
        changes.push(fileDiff);
        
        // Update progress
        loadedCount++;
        this.emit('progress', {
          loaded: loadedCount,
          total: summary.files.length
        });
      }
      
      // Combine into final diff
      return {
        files: summary.files,
        changes,
        stats: summary.stats
      };
    } finally {
      if (this.currentOperation === abortController) {
        this.currentOperation = null;
      }
    }
  }
  
  /**
   * Register a progress callback
   * @param callback Progress callback
   * @returns Function to remove the callback
   */
  onProgress(callback: ProgressCallback): () => void {
    this.on('progress', callback);
    return () => this.off('progress', callback);
  }
  
  /**
   * Cancel the current operation
   */
  cancelOperation(): void {
    if (this.currentOperation) {
      this.currentOperation.abort();
      this.currentOperation = null;
    }
  }
  
  /**
   * Ensure the calculator is initialized
   */
  private async ensureInitialized(): Promise<void> {
    if (!this.initialized) {
      await this.initialize();
    }
  }
}
```

### 11. Create Factory for Large Repository Handling
```typescript
// src/factories/repositoryHandlingFactory.ts
import { RepositorySizeAnalyzer } from '../services/repositorySizeAnalyzer';
import { GitDataWindowingService } from '../services/gitDataWindowingService';
import { GitStatusCache } from '../services/gitStatusCache';
import { SmartDiffCalculator } from '../services/smartDiffCalculator';
import { GitOperationsService } from '../services/gitOperations';
import { BackgroundWorker } from '../services/backgroundWorker';
import { CacheManager } from '../services/cacheManager';

/**
 * Create repository size analyzer
 */
export function createRepositorySizeAnalyzer(
  gitOps: GitOperationsService
): RepositorySizeAnalyzer {
  return new RepositorySizeAnalyzer(gitOps);
}

/**
 * Create git data windowing service
 */
export function createGitDataWindowingService(
  gitOps: GitOperationsService,
  worker: BackgroundWorker
): GitDataWindowingService {
  const service = new GitDataWindowingService(gitOps, worker);
  
  // Initialize in background
  service.initialize().catch(error => {
    console.error('Failed to initialize GitDataWindowingService:', error);
  });
  
  return service;
}

/**
 * Create git status cache
 */
export function createGitStatusCache(
  gitOps: GitOperationsService,
  cacheManager: CacheManager,
  ttl: number = 10
): GitStatusCache {
  return new GitStatusCache(gitOps, cacheManager, ttl);
}

/**
 * Create smart diff calculator
 */
export function createSmartDiffCalculator(
  gitOps: GitOperationsService,
  repoAnalyzer: RepositorySizeAnalyzer
): SmartDiffCalculator {
  const calculator = new SmartDiffCalculator(gitOps, repoAnalyzer);
  
  // Initialize in background
  calculator.initialize().catch(error => {
    console.error('Failed to initialize SmartDiffCalculator:', error);
  });
  
  return calculator;
}

/**
 * Configure large repository handling
 */
export async function configureLargeRepositoryHandling(
  gitOps: GitOperationsService,
  worker: BackgroundWorker,
  cacheManager: CacheManager
): Promise<{
  analyzer: RepositorySizeAnalyzer;
  windowing: GitDataWindowingService;
  statusCache: GitStatusCache;
  diffCalculator: SmartDiffCalculator;
}> {
  // Create services
  const analyzer = createRepositorySizeAnalyzer(gitOps);
  const windowing = createGitDataWindowingService(gitOps, worker);
  const statusCache = createGitStatusCache(gitOps, cacheManager);
  const diffCalculator = createSmartDiffCalculator(gitOps, analyzer);
  
  // Analyze repository
  const analysis = await analyzer.analyzeRepository();
  
  // Log optimization suggestions if it's a large repository
  if (analysis.isLarge) {
    const suggestions = analyzer.generateOptimizationSuggestions(analysis);
    console.debug('Large repository detected. Optimization suggestions:');
    for (const suggestion of suggestions) {
      console.debug(`- ${suggestion}`);
    }
  }
  
  return {
    analyzer,
    windowing,
    statusCache,
    diffCalculator
  };
}
```

### 12. Update Main Export Files
```typescript
// src/services/index.ts
export * from './repositorySizeAnalyzer';
export * from './gitDataWindowingService';
export * from './gitStatusCache';
export * from './smartDiffCalculator';
// ... other exports
```

```typescript
// src/components/index.ts
export * from './virtualList';
// ... other exports
```

```typescript
// src/factories/index.ts
export * from './repositoryHandlingFactory';
// ... other exports
```

## Definition of Done
- The application can efficiently handle large Git repositories
- Virtual list components are used for large data sets
- Incremental loading is implemented for large diffs
- Status cache is implemented for fast access to repository status
- Repository size analysis guides optimization strategies
- Performance remains responsive even with large repositories
- All test cases pass and achieve adequate coverage

## Potential Blockers
- Very large repositories may still cause performance issues
- Complex diff operations can be memory-intensive
- Balancing responsiveness with comprehensive data access
- Incremental loading may complicate UI implementations

## Next Steps
- Memory Usage Optimizations (4.3.3)
- Analytics Dashboard Implementation (5.1.1)