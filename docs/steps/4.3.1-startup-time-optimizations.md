# 4.3.1 Startup Time Optimizations

## Overview
This step focuses on optimizing the application startup time to provide a responsive user experience, even in large repositories. It implements techniques like lazy loading, caching, parallel processing, and on-demand resource initialization to ensure the tool starts quickly and remains responsive during use.

## Dependencies
- Git Repository Detection (1.3.1)
- Git Operations Interface (1.3.2)
- Configuration Schema Definition (3.3.2)
- Per-Project Settings Implementation (3.3.3)

## Prerequisites
- Working Git Repository Detection (1.3.1)
- Working Git Operations Interface (1.3.2)
- Completed Configuration Schema Definition (3.3.2)
- Completed Per-Project Settings Implementation (3.3.3)

## Implementation Order
1. Create profiling system
2. Implement lazy loading framework
3. Add resource cache management
4. Develop background processing
5. Optimize configuration loading

## Development Guidelines
- Focus on perceived performance as well as actual performance
- Use asynchronous operations wherever possible
- Implement proper progress indicators for slow operations
- Keep critical path operations to a minimum during startup
- Use caching judiciously, with appropriate cache invalidation

## Tasks

### 1. Create Test File for Application Profiler
```typescript
// __tests__/services/profiler.test.ts
import { Profiler } from '../../src/services/profiler';

describe('Profiler', () => {
  let profiler: Profiler;
  
  beforeEach(() => {
    // Mock Date.now to control timing
    jest.spyOn(Date, 'now').mockImplementation(() => 1000);
    
    profiler = new Profiler();
  });
  
  afterEach(() => {
    jest.restoreAllMocks();
  });
  
  test('should measure execution time of a function', () => {
    // Setup mock timing
    jest.spyOn(Date, 'now')
      .mockImplementationOnce(() => 1000)  // start time
      .mockImplementationOnce(() => 1200); // end time
    
    const result = profiler.measure('test-function', () => {
      return 'result';
    });
    
    expect(result).toBe('result');
    expect(profiler.getMeasurement('test-function')).toBe(200);
  });
  
  test('should measure execution time of an async function', async () => {
    // Setup mock timing
    jest.spyOn(Date, 'now')
      .mockImplementationOnce(() => 1000)  // start time
      .mockImplementationOnce(() => 1500); // end time
    
    const result = await profiler.measureAsync('async-function', async () => {
      return 'async result';
    });
    
    expect(result).toBe('async result');
    expect(profiler.getMeasurement('async-function')).toBe(500);
  });
  
  test('should start and end measurements manually', () => {
    // Setup mock timing
    jest.spyOn(Date, 'now')
      .mockImplementationOnce(() => 1000)  // start time
      .mockImplementationOnce(() => 1800); // end time
    
    profiler.start('manual-operation');
    // Simulate some work
    profiler.end('manual-operation');
    
    expect(profiler.getMeasurement('manual-operation')).toBe(800);
  });
  
  test('should get all measurements', () => {
    // Setup mock timing for multiple operations
    jest.spyOn(Date, 'now')
      .mockImplementationOnce(() => 1000)
      .mockImplementationOnce(() => 1200)
      .mockImplementationOnce(() => 1200)
      .mockImplementationOnce(() => 1500);
    
    profiler.measure('operation-1', () => {});
    profiler.measure('operation-2', () => {});
    
    const measurements = profiler.getAllMeasurements();
    expect(measurements['operation-1']).toBe(200);
    expect(measurements['operation-2']).toBe(300);
  });
  
  test('should reset measurements', () => {
    profiler.measure('test-function', () => {});
    expect(profiler.getAllMeasurements()).toHaveProperty('test-function');
    
    profiler.reset();
    expect(profiler.getAllMeasurements()).toEqual({});
  });
  
  test('should mark significant operations', () => {
    profiler.mark('app-start');
    
    const marks = profiler.getMarks();
    expect(marks).toHaveProperty('app-start');
    expect(marks['app-start']).toBe(1000);
  });
  
  test('should calculate duration between marks', () => {
    // Setup mock timing for marks
    jest.spyOn(Date, 'now')
      .mockImplementationOnce(() => 1000)
      .mockImplementationOnce(() => 2500);
    
    profiler.mark('load-start');
    profiler.mark('load-end');
    
    expect(profiler.getDurationBetweenMarks('load-start', 'load-end')).toBe(1500);
  });
});
```

### 2. Create Test File for Resource Manager
```typescript
// __tests__/services/resourceManager.test.ts
import { ResourceManager } from '../../src/services/resourceManager';

describe('ResourceManager', () => {
  let resourceManager: ResourceManager;
  
  beforeEach(() => {
    resourceManager = new ResourceManager();
  });
  
  test('should register and retrieve a resource factory', () => {
    const factory = jest.fn().mockResolvedValue('resource-value');
    
    resourceManager.register('test-resource', factory);
    
    expect(resourceManager.hasResource('test-resource')).toBe(true);
    expect(factory).not.toHaveBeenCalled(); // Factory shouldn't be called until resource is requested
  });
  
  test('should lazily load a resource on first access', async () => {
    const factory = jest.fn().mockResolvedValue('resource-value');
    resourceManager.register('lazy-resource', factory);
    
    const resource = await resourceManager.get('lazy-resource');
    
    expect(resource).toBe('resource-value');
    expect(factory).toHaveBeenCalledTimes(1);
    
    // Second access should use cached value
    const cachedResource = await resourceManager.get('lazy-resource');
    expect(cachedResource).toBe('resource-value');
    expect(factory).toHaveBeenCalledTimes(1); // Still only called once
  });
  
  test('should handle resource factory errors', async () => {
    const factory = jest.fn().mockRejectedValue(new Error('Factory error'));
    resourceManager.register('error-resource', factory);
    
    await expect(resourceManager.get('error-resource')).rejects.toThrow('Factory error');
  });
  
  test('should throw error when requesting non-existent resource', async () => {
    await expect(resourceManager.get('non-existent')).rejects.toThrow('Resource not registered: non-existent');
  });
  
  test('should invalidate a cached resource', async () => {
    const factory = jest.fn().mockResolvedValue('resource-value');
    resourceManager.register('cached-resource', factory);
    
    // First access
    await resourceManager.get('cached-resource');
    expect(factory).toHaveBeenCalledTimes(1);
    
    // Invalidate the resource
    resourceManager.invalidate('cached-resource');
    
    // Next access should call factory again
    await resourceManager.get('cached-resource');
    expect(factory).toHaveBeenCalledTimes(2);
  });
  
  test('should invalidate all cached resources', async () => {
    const factory1 = jest.fn().mockResolvedValue('resource-1');
    const factory2 = jest.fn().mockResolvedValue('resource-2');
    
    resourceManager.register('resource-1', factory1);
    resourceManager.register('resource-2', factory2);
    
    // Access both resources
    await resourceManager.get('resource-1');
    await resourceManager.get('resource-2');
    
    expect(factory1).toHaveBeenCalledTimes(1);
    expect(factory2).toHaveBeenCalledTimes(1);
    
    // Invalidate all resources
    resourceManager.invalidateAll();
    
    // Access both resources again
    await resourceManager.get('resource-1');
    await resourceManager.get('resource-2');
    
    expect(factory1).toHaveBeenCalledTimes(2);
    expect(factory2).toHaveBeenCalledTimes(2);
  });
  
  test('should provide status information about resources', async () => {
    const factory = jest.fn().mockResolvedValue('resource-value');
    resourceManager.register('status-resource', factory);
    
    // Before access
    let status = resourceManager.getResourceStatus();
    expect(status['status-resource']).toBe('registered');
    
    // During loading
    const promise = resourceManager.get('status-resource');
    status = resourceManager.getResourceStatus();
    expect(status['status-resource']).toBe('loading');
    
    // After loading
    await promise;
    status = resourceManager.getResourceStatus();
    expect(status['status-resource']).toBe('loaded');
    
    // After invalidation
    resourceManager.invalidate('status-resource');
    status = resourceManager.getResourceStatus();
    expect(status['status-resource']).toBe('registered');
  });
});
```

### 3. Create Test File for Background Worker
```typescript
// __tests__/services/backgroundWorker.test.ts
import { BackgroundWorker } from '../../src/services/backgroundWorker';

describe('BackgroundWorker', () => {
  let worker: BackgroundWorker;
  
  beforeEach(() => {
    worker = new BackgroundWorker();
  });
  
  test('should execute task in background', async () => {
    const task = jest.fn().mockResolvedValue('result');
    
    const promise = worker.execute('test-task', task);
    
    // Task should be running in background
    expect(worker.isRunning('test-task')).toBe(true);
    
    // Wait for result
    const result = await promise;
    expect(result).toBe('result');
    expect(task).toHaveBeenCalled();
    expect(worker.isRunning('test-task')).toBe(false);
  });
  
  test('should handle task errors', async () => {
    const task = jest.fn().mockRejectedValue(new Error('Task error'));
    
    const promise = worker.execute('error-task', task);
    
    await expect(promise).rejects.toThrow('Task error');
    expect(worker.isRunning('error-task')).toBe(false);
  });
  
  test('should cancel a running task', async () => {
    // Create a task that waits for cancellation
    let isCancelled = false;
    const task = jest.fn().mockImplementation(() => {
      return new Promise((resolve, reject) => {
        const checkCancellation = setInterval(() => {
          if (isCancelled) {
            clearInterval(checkCancellation);
            reject(new Error('Task cancelled'));
          }
        }, 100);
      });
    });
    
    // Start the task
    const promise = worker.execute('cancellable-task', task);
    
    // Task should be running
    expect(worker.isRunning('cancellable-task')).toBe(true);
    
    // Set up cancellation callback
    worker.onCancel('cancellable-task', () => {
      isCancelled = true;
    });
    
    // Cancel the task
    worker.cancel('cancellable-task');
    
    // Task should reject with cancellation error
    await expect(promise).rejects.toThrow('Task cancelled');
    expect(worker.isRunning('cancellable-task')).toBe(false);
  });
  
  test('should execute multiple tasks in parallel', async () => {
    const tasks = [
      jest.fn().mockResolvedValue('result-1'),
      jest.fn().mockResolvedValue('result-2'),
      jest.fn().mockResolvedValue('result-3')
    ];
    
    const promises = [
      worker.execute('task-1', tasks[0]),
      worker.execute('task-2', tasks[1]),
      worker.execute('task-3', tasks[2])
    ];
    
    // All tasks should be running
    expect(worker.isRunning('task-1')).toBe(true);
    expect(worker.isRunning('task-2')).toBe(true);
    expect(worker.isRunning('task-3')).toBe(true);
    
    // Wait for all results
    const results = await Promise.all(promises);
    
    expect(results).toEqual(['result-1', 'result-2', 'result-3']);
    expect(tasks[0]).toHaveBeenCalled();
    expect(tasks[1]).toHaveBeenCalled();
    expect(tasks[2]).toHaveBeenCalled();
    
    // No tasks should be running
    expect(worker.isRunning('task-1')).toBe(false);
    expect(worker.isRunning('task-2')).toBe(false);
    expect(worker.isRunning('task-3')).toBe(false);
  });
  
  test('should provide task status information', async () => {
    const longRunningTask = jest.fn().mockImplementation(() => {
      return new Promise(resolve => {
        setTimeout(() => resolve('delayed-result'), 100);
      });
    });
    
    const promise = worker.execute('status-task', longRunningTask);
    
    // Task should be running
    expect(worker.getTaskStatus()).toEqual({
      'status-task': {
        running: true,
        startTime: expect.any(Number)
      }
    });
    
    // Wait for task to complete
    await promise;
    
    // Task should be completed
    expect(worker.getTaskStatus()).toEqual({});
  });
});
```

### 4. Create Test File for Cache Manager
```typescript
// __tests__/services/cacheManager.test.ts
import { CacheManager } from '../../src/services/cacheManager';
import * as fs from 'fs/promises';
import * as path from 'path';

// Mock file system operations
jest.mock('fs/promises');
jest.mock('path', () => ({
  join: jest.fn((...args) => args.join('/'))
}));

describe('CacheManager', () => {
  let cacheManager: CacheManager;
  const mockCachePath = '/mock/cache/path';
  
  beforeEach(() => {
    jest.clearAllMocks();
    
    // Mock fs.mkdir to do nothing
    (fs.mkdir as jest.Mock).mockResolvedValue(undefined);
    
    cacheManager = new CacheManager(mockCachePath);
  });
  
  test('should initialize cache directory', async () => {
    await cacheManager.initialize();
    
    expect(fs.mkdir).toHaveBeenCalledWith(mockCachePath, { recursive: true });
  });
  
  test('should store item in cache', async () => {
    // Mock fs.writeFile to do nothing
    (fs.writeFile as jest.Mock).mockResolvedValue(undefined);
    
    const data = { key: 'value' };
    await cacheManager.set('test-key', data);
    
    expect(fs.writeFile).toHaveBeenCalledWith(
      expect.stringContaining('test-key'),
      JSON.stringify({
        data,
        timestamp: expect.any(Number),
        ttl: null
      })
    );
  });
  
  test('should store item with TTL', async () => {
    (fs.writeFile as jest.Mock).mockResolvedValue(undefined);
    
    const data = { key: 'value' };
    const ttl = 60000; // 1 minute
    await cacheManager.set('ttl-key', data, ttl);
    
    expect(fs.writeFile).toHaveBeenCalledWith(
      expect.stringContaining('ttl-key'),
      JSON.stringify({
        data,
        timestamp: expect.any(Number),
        ttl
      })
    );
  });
  
  test('should retrieve valid item from cache', async () => {
    // Mock fs.readFile to return cached data
    const cachedData = {
      data: { key: 'cached-value' },
      timestamp: Date.now(),
      ttl: null
    };
    (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify(cachedData));
    
    const result = await cacheManager.get('cached-key');
    
    expect(result).toEqual(cachedData.data);
    expect(fs.readFile).toHaveBeenCalledWith(
      expect.stringContaining('cached-key'),
      'utf-8'
    );
  });
  
  test('should not retrieve expired item from cache', async () => {
    // Mock fs.readFile to return expired cached data
    const cachedData = {
      data: { key: 'expired-value' },
      timestamp: Date.now() - 120000, // 2 minutes ago
      ttl: 60000 // 1 minute TTL
    };
    (fs.readFile as jest.Mock).mockResolvedValue(JSON.stringify(cachedData));
    (fs.unlink as jest.Mock).mockResolvedValue(undefined);
    
    const result = await cacheManager.get('expired-key');
    
    expect(result).toBeNull();
    expect(fs.unlink).toHaveBeenCalledWith(
      expect.stringContaining('expired-key')
    );
  });
  
  test('should handle cache miss', async () => {
    // Mock fs.readFile to throw ENOENT error
    (fs.readFile as jest.Mock).mockRejectedValue({ code: 'ENOENT' });
    
    const result = await cacheManager.get('missing-key');
    
    expect(result).toBeNull();
  });
  
  test('should delete item from cache', async () => {
    (fs.unlink as jest.Mock).mockResolvedValue(undefined);
    
    await cacheManager.delete('delete-key');
    
    expect(fs.unlink).toHaveBeenCalledWith(
      expect.stringContaining('delete-key')
    );
  });
  
  test('should handle delete of non-existent item', async () => {
    (fs.unlink as jest.Mock).mockRejectedValue({ code: 'ENOENT' });
    
    await expect(cacheManager.delete('non-existent')).resolves.not.toThrow();
  });
  
  test('should clear all cache items', async () => {
    // Mock fs.readdir and fs.unlink
    (fs.readdir as jest.Mock).mockResolvedValue(['item1.json', 'item2.json']);
    (fs.unlink as jest.Mock).mockResolvedValue(undefined);
    
    await cacheManager.clear();
    
    expect(fs.readdir).toHaveBeenCalledWith(mockCachePath);
    expect(fs.unlink).toHaveBeenCalledTimes(2);
    expect(fs.unlink).toHaveBeenCalledWith(
      expect.stringContaining('item1.json')
    );
    expect(fs.unlink).toHaveBeenCalledWith(
      expect.stringContaining('item2.json')
    );
  });
  
  test('should get cache stats', async () => {
    // Mock fs.readdir and fs.stat
    (fs.readdir as jest.Mock).mockResolvedValue(['item1.json', 'item2.json']);
    (fs.stat as jest.Mock).mockResolvedValue({
      size: 1024,
      mtime: new Date()
    });
    
    const stats = await cacheManager.getStats();
    
    expect(stats).toEqual({
      itemCount: 2,
      totalSize: 2048,
      oldestItem: expect.any(Date),
      newestItem: expect.any(Date)
    });
  });
});
```

### 5. Create Test File for Configuration Optimizer
```typescript
// __tests__/services/configurationOptimizer.test.ts
import { ConfigurationOptimizer } from '../../src/services/configurationOptimizer';
import { ConfigurationManager } from '../../src/services/configurationManager';
import { CacheManager } from '../../src/services/cacheManager';

// Mock dependencies
jest.mock('../../src/services/configurationManager');
jest.mock('../../src/services/cacheManager');

describe('ConfigurationOptimizer', () => {
  let optimizer: ConfigurationOptimizer;
  let mockConfigManager: jest.Mocked<ConfigurationManager>;
  let mockCacheManager: jest.Mocked<CacheManager>;
  
  const mockConfig = {
    projectName: 'test-project',
    templates: [
      { id: 'template1', name: 'Template 1' },
      { id: 'template2', name: 'Template 2' }
    ],
    settings: {
      maxLineLength: 100,
      defaultTemplate: 'template1'
    }
  };
  
  beforeEach(() => {
    mockConfigManager = new ConfigurationManager() as jest.Mocked<ConfigurationManager>;
    mockCacheManager = new CacheManager('') as jest.Mocked<CacheManager>;
    
    mockConfigManager.getConfiguration.mockResolvedValue(mockConfig);
    mockConfigManager.getConfigHash.mockResolvedValue('config-hash-123');
    
    mockCacheManager.get.mockResolvedValue(null); // No cached value by default
    mockCacheManager.set.mockResolvedValue(undefined);
    
    optimizer = new ConfigurationOptimizer(mockConfigManager, mockCacheManager);
  });
  
  test('should get optimized configuration from cache if available', async () => {
    // Mock cached config
    const cachedConfig = {
      ...mockConfig,
      _optimized: true
    };
    mockCacheManager.get.mockResolvedValue(cachedConfig);
    
    const config = await optimizer.getOptimizedConfiguration();
    
    expect(config).toEqual(cachedConfig);
    expect(mockCacheManager.get).toHaveBeenCalledWith('config-hash-123');
    expect(mockConfigManager.getConfiguration).not.toHaveBeenCalled();
  });
  
  test('should optimize and cache configuration if not in cache', async () => {
    mockCacheManager.get.mockResolvedValue(null);
    
    const config = await optimizer.getOptimizedConfiguration();
    
    expect(config).toEqual({
      ...mockConfig,
      _optimized: true
    });
    expect(mockConfigManager.getConfiguration).toHaveBeenCalled();
    expect(mockCacheManager.set).toHaveBeenCalledWith(
      'config-hash-123',
      expect.objectContaining({ _optimized: true }),
      expect.any(Number)
    );
  });
  
  test('should refresh cache when invalidateCache is called', async () => {
    // Get config first time (should cache)
    await optimizer.getOptimizedConfiguration();
    
    // Invalidate cache
    await optimizer.invalidateCache();
    
    // Get config second time (should rebuild cache)
    await optimizer.getOptimizedConfiguration();
    
    expect(mockConfigManager.getConfiguration).toHaveBeenCalledTimes(2);
    expect(mockCacheManager.delete).toHaveBeenCalledWith('config-hash-123');
  });
  
  test('should subscribe to configuration changes', async () => {
    // Setup mock change handler
    const mockChangeHandler = jest.fn();
    optimizer.onConfigurationChanged(mockChangeHandler);
    
    // Trigger a change
    const changeCallback = mockConfigManager.subscribeToChanges.mock.calls[0][0];
    changeCallback();
    
    // Change handler should be called
    expect(mockChangeHandler).toHaveBeenCalled();
    
    // Cache should be invalidated
    expect(mockCacheManager.delete).toHaveBeenCalledWith('config-hash-123');
  });
  
  test('should optimize configuration', async () => {
    // Mock specific config with optimization opportunities
    const complexConfig = {
      templates: Array(100).fill(0).map((_, i) => ({
        id: `template${i}`,
        name: `Template ${i}`,
        description: `Description for template ${i}`,
        fields: Array(10).fill(0).map((_, j) => ({
          id: `field${j}`,
          name: `Field ${j}`,
          type: 'string',
          defaultValue: `default ${j}`
        }))
      })),
      patterns: Array(50).fill(0).map((_, i) => ({
        id: `pattern${i}`,
        regex: `regex${i}`,
        description: `Description for pattern ${i}`
      }))
    };
    
    mockConfigManager.getConfiguration.mockResolvedValue(complexConfig);
    
    const optimizedConfig = await optimizer.getOptimizedConfiguration();
    
    // Should contain index lookup tables
    expect(optimizedConfig).toHaveProperty('_indexes');
    expect(optimizedConfig._indexes).toHaveProperty('templateById');
    expect(optimizedConfig._indexes).toHaveProperty('patternById');
    
    // Original data should still be present
    expect(optimizedConfig.templates).toEqual(complexConfig.templates);
    expect(optimizedConfig.patterns).toEqual(complexConfig.patterns);
  });
});
```

### 6. Implement Application Profiler
```typescript
// src/services/profiler.ts
/**
 * Service for profiling application performance
 */
export class Profiler {
  private measurements: Record<string, number> = {};
  private marks: Record<string, number> = {};
  private startTimes: Record<string, number> = {};
  
  /**
   * Measure the execution time of a function
   * @param name Name of the operation to measure
   * @param fn Function to measure
   * @returns Return value of the function
   */
  measure<T>(name: string, fn: () => T): T {
    this.start(name);
    const result = fn();
    this.end(name);
    return result;
  }
  
  /**
   * Measure the execution time of an async function
   * @param name Name of the operation to measure
   * @param fn Async function to measure
   * @returns Promise resolving to the return value of the function
   */
  async measureAsync<T>(name: string, fn: () => Promise<T>): Promise<T> {
    this.start(name);
    try {
      const result = await fn();
      this.end(name);
      return result;
    } catch (error) {
      this.end(name);
      throw error;
    }
  }
  
  /**
   * Start measuring an operation
   * @param name Name of the operation
   */
  start(name: string): void {
    this.startTimes[name] = Date.now();
  }
  
  /**
   * End measuring an operation and record the duration
   * @param name Name of the operation
   */
  end(name: string): void {
    if (!this.startTimes[name]) {
      console.warn(`No start time found for: ${name}`);
      return;
    }
    
    const duration = Date.now() - this.startTimes[name];
    this.measurements[name] = duration;
    delete this.startTimes[name];
  }
  
  /**
   * Get the duration of a measured operation
   * @param name Name of the operation
   * @returns Duration in milliseconds or undefined if not measured
   */
  getMeasurement(name: string): number | undefined {
    return this.measurements[name];
  }
  
  /**
   * Get all measurements
   * @returns Record of operation names to durations
   */
  getAllMeasurements(): Record<string, number> {
    return { ...this.measurements };
  }
  
  /**
   * Mark a point in time with a name
   * @param name Name of the mark
   */
  mark(name: string): void {
    this.marks[name] = Date.now();
  }
  
  /**
   * Get all marks
   * @returns Record of mark names to timestamps
   */
  getMarks(): Record<string, number> {
    return { ...this.marks };
  }
  
  /**
   * Calculate duration between two marks
   * @param startMark Name of the start mark
   * @param endMark Name of the end mark
   * @returns Duration in milliseconds or undefined if marks don't exist
   */
  getDurationBetweenMarks(startMark: string, endMark: string): number | undefined {
    if (!this.marks[startMark] || !this.marks[endMark]) {
      return undefined;
    }
    
    return this.marks[endMark] - this.marks[startMark];
  }
  
  /**
   * Reset all measurements and marks
   */
  reset(): void {
    this.measurements = {};
    this.startTimes = {};
    this.marks = {};
  }
  
  /**
   * Get a report of all measurements and marks
   * @returns Formatted performance report
   */
  getReport(): string {
    const lines: string[] = [];
    
    lines.push('=== Performance Report ===');
    lines.push('Measurements:');
    
    const sortedMeasurements = Object.entries(this.measurements)
      .sort((a, b) => b[1] - a[1]); // Sort by duration (desc)
    
    for (const [name, duration] of sortedMeasurements) {
      lines.push(`  ${name}: ${duration}ms`);
    }
    
    lines.push('\nMarks:');
    for (const [name, timestamp] of Object.entries(this.marks)) {
      const time = new Date(timestamp).toISOString();
      lines.push(`  ${name}: ${time}`);
    }
    
    lines.push('========================');
    return lines.join('\n');
  }
}

// Create a global instance for convenience
export const profiler = new Profiler();
```

### 7. Implement Resource Manager
```typescript
// src/services/resourceManager.ts
import { profiler } from './profiler';

type ResourceFactory<T> = () => Promise<T>;
type ResourceStatus = 'registered' | 'loading' | 'loaded' | 'error';

interface ResourceEntry<T> {
  factory: ResourceFactory<T>;
  status: ResourceStatus;
  promise?: Promise<T>;
  value?: T;
  error?: Error;
}

/**
 * Manages lazy-loaded application resources
 */
export class ResourceManager {
  private resources: Map<string, ResourceEntry<any>> = new Map();
  
  /**
   * Register a resource factory
   * @param name Resource name
   * @param factory Async factory function to create the resource
   */
  register<T>(name: string, factory: ResourceFactory<T>): void {
    this.resources.set(name, {
      factory,
      status: 'registered'
    });
  }
  
  /**
   * Check if a resource is registered
   * @param name Resource name
   * @returns True if the resource is registered
   */
  hasResource(name: string): boolean {
    return this.resources.has(name);
  }
  
  /**
   * Get a resource, loading it if necessary
   * @param name Resource name
   * @returns Promise resolving to the resource
   */
  async get<T>(name: string): Promise<T> {
    const entry = this.resources.get(name);
    
    if (!entry) {
      throw new Error(`Resource not registered: ${name}`);
    }
    
    // If resource is already loaded, return it
    if (entry.status === 'loaded' && entry.value !== undefined) {
      return entry.value;
    }
    
    // If resource is currently loading, return the existing promise
    if (entry.status === 'loading' && entry.promise) {
      return entry.promise;
    }
    
    // Start loading the resource
    entry.status = 'loading';
    entry.promise = profiler.measureAsync(`load-resource:${name}`, async () => {
      try {
        const value = await entry.factory();
        entry.value = value;
        entry.status = 'loaded';
        return value;
      } catch (error) {
        entry.error = error as Error;
        entry.status = 'error';
        throw error;
      }
    });
    
    return entry.promise;
  }
  
  /**
   * Invalidate a cached resource
   * @param name Resource name
   */
  invalidate(name: string): void {
    const entry = this.resources.get(name);
    
    if (entry) {
      // Reset to initial state, but keep the factory
      const { factory } = entry;
      this.resources.set(name, {
        factory,
        status: 'registered'
      });
    }
  }
  
  /**
   * Invalidate all cached resources
   */
  invalidateAll(): void {
    for (const name of this.resources.keys()) {
      this.invalidate(name);
    }
  }
  
  /**
   * Get the current status of all resources
   * @returns Map of resource names to statuses
   */
  getResourceStatus(): Record<string, ResourceStatus> {
    const status: Record<string, ResourceStatus> = {};
    
    for (const [name, entry] of this.resources.entries()) {
      status[name] = entry.status;
    }
    
    return status;
  }
  
  /**
   * Preload specific resources
   * @param names Resource names to preload
   * @returns Promise resolving when all resources are loaded
   */
  async preload(names: string[]): Promise<void> {
    await Promise.all(names.map(name => this.get(name)));
  }
  
  /**
   * Get all loaded resources
   * @returns Map of resource names to values
   */
  getLoadedResources(): Record<string, any> {
    const loaded: Record<string, any> = {};
    
    for (const [name, entry] of this.resources.entries()) {
      if (entry.status === 'loaded' && entry.value !== undefined) {
        loaded[name] = entry.value;
      }
    }
    
    return loaded;
  }
}
```

### 8. Implement Background Worker
```typescript
// src/services/backgroundWorker.ts
import { profiler } from './profiler';

type TaskFunction<T> = () => Promise<T>;
type CancellationCallback = () => void;

interface TaskContext {
  id: string;
  startTime: number;
  cancellationCallbacks: CancellationCallback[];
}

/**
 * Manages background tasks and parallel processing
 */
export class BackgroundWorker {
  private runningTasks: Map<string, TaskContext> = new Map();
  
  /**
   * Execute a task in the background
   * @param id Unique task identifier
   * @param task Async task function
   * @returns Promise resolving to the task result
   */
  async execute<T>(id: string, task: TaskFunction<T>): Promise<T> {
    // Create task context
    const context: TaskContext = {
      id,
      startTime: Date.now(),
      cancellationCallbacks: []
    };
    
    // Register running task
    this.runningTasks.set(id, context);
    
    // Execute the task and measure performance
    try {
      return await profiler.measureAsync(`background-task:${id}`, async () => {
        return await task();
      });
    } finally {
      // Clean up task context
      this.runningTasks.delete(id);
    }
  }
  
  /**
   * Check if a task is currently running
   * @param id Task identifier
   * @returns True if the task is running
   */
  isRunning(id: string): boolean {
    return this.runningTasks.has(id);
  }
  
  /**
   * Get the status of all running tasks
   * @returns Map of task IDs to status information
   */
  getTaskStatus(): Record<string, { running: boolean; startTime: number }> {
    const status: Record<string, { running: boolean; startTime: number }> = {};
    
    for (const [id, context] of this.runningTasks.entries()) {
      status[id] = {
        running: true,
        startTime: context.startTime
      };
    }
    
    return status;
  }
  
  /**
   * Register a callback for task cancellation
   * @param id Task identifier
   * @param callback Function to call when task is cancelled
   */
  onCancel(id: string, callback: CancellationCallback): void {
    const context = this.runningTasks.get(id);
    if (context) {
      context.cancellationCallbacks.push(callback);
    }
  }
  
  /**
   * Cancel a running task
   * @param id Task identifier
   * @returns True if the task was cancelled, false if not running
   */
  cancel(id: string): boolean {
    const context = this.runningTasks.get(id);
    if (!context) {
      return false;
    }
    
    // Execute all cancellation callbacks
    for (const callback of context.cancellationCallbacks) {
      try {
        callback();
      } catch (error) {
        console.error(`Error in cancellation callback for task ${id}:`, error);
      }
    }
    
    return true;
  }
  
  /**
   * Cancel all running tasks
   * @returns Number of tasks cancelled
   */
  cancelAll(): number {
    const taskIds = Array.from(this.runningTasks.keys());
    let cancelCount = 0;
    
    for (const id of taskIds) {
      if (this.cancel(id)) {
        cancelCount++;
      }
    }
    
    return cancelCount;
  }
  
  /**
   * Get the number of currently running tasks
   * @returns Number of running tasks
   */
  getRunningTaskCount(): number {
    return this.runningTasks.size;
  }
  
  /**
   * Execute multiple tasks in parallel with a concurrency limit
   * @param tasks Array of task functions
   * @param concurrency Maximum number of tasks to run simultaneously
   * @returns Promise resolving to array of results
   */
  async executeParallel<T>(
    tasks: Array<{ id: string; task: TaskFunction<T> }>,
    concurrency: number = 4
  ): Promise<T[]> {
    const results: T[] = new Array(tasks.length);
    let nextTaskIndex = 0;
    
    // Helper function to run a task at a specific index
    const runTaskAtIndex = async (index: number): Promise<void> => {
      const { id, task } = tasks[index];
      results[index] = await this.execute(id, task);
    };
    
    // Process tasks with concurrency limit
    const runningTasks: Promise<void>[] = [];
    
    // Start initial batch of tasks
    while (nextTaskIndex < tasks.length && runningTasks.length < concurrency) {
      runningTasks.push(runTaskAtIndex(nextTaskIndex++));
    }
    
    // Process remaining tasks as earlier ones complete
    while (runningTasks.length > 0) {
      await Promise.race(runningTasks);
      
      // Remove completed tasks
      const completedIndex = runningTasks.findIndex(t => t.status === 'fulfilled');
      if (completedIndex >= 0) {
        runningTasks.splice(completedIndex, 1);
      }
      
      // Add new task if available
      if (nextTaskIndex < tasks.length) {
        runningTasks.push(runTaskAtIndex(nextTaskIndex++));
      }
    }
    
    return results;
  }
}
```

### 9. Implement Cache Manager
```typescript
// src/services/cacheManager.ts
import * as fs from 'fs/promises';
import * as path from 'path';
import { profiler } from './profiler';

interface CacheEntry<T> {
  data: T;
  timestamp: number;
  ttl: number | null;
}

interface CacheStats {
  itemCount: number;
  totalSize: number;
  oldestItem: Date;
  newestItem: Date;
}

/**
 * Manages persistent caching of application data
 */
export class CacheManager {
  constructor(private cachePath: string) {}
  
  /**
   * Initialize the cache manager
   */
  async initialize(): Promise<void> {
    await fs.mkdir(this.cachePath, { recursive: true });
  }
  
  /**
   * Store an item in the cache
   * @param key Cache key
   * @param data Data to cache
   * @param ttl Optional time-to-live in milliseconds
   */
  async set<T>(key: string, data: T, ttl: number | null = null): Promise<void> {
    const filePath = this.getCacheFilePath(key);
    const entry: CacheEntry<T> = {
      data,
      timestamp: Date.now(),
      ttl
    };
    
    await fs.writeFile(filePath, JSON.stringify(entry));
  }
  
  /**
   * Retrieve an item from the cache
   * @param key Cache key
   * @returns Cached data or null if not found or expired
   */
  async get<T>(key: string): Promise<T | null> {
    const filePath = this.getCacheFilePath(key);
    
    try {
      const data = await fs.readFile(filePath, 'utf-8');
      const entry: CacheEntry<T> = JSON.parse(data);
      
      // Check if entry is expired
      if (entry.ttl !== null) {
        const now = Date.now();
        const expiryTime = entry.timestamp + entry.ttl;
        
        if (now > expiryTime) {
          // Entry is expired, delete it
          await this.delete(key);
          return null;
        }
      }
      
      return entry.data;
    } catch (error) {
      // File doesn't exist or other error
      return null;
    }
  }
  
  /**
   * Delete an item from the cache
   * @param key Cache key
   */
  async delete(key: string): Promise<void> {
    const filePath = this.getCacheFilePath(key);
    
    try {
      await fs.unlink(filePath);
    } catch (error) {
      // Ignore errors if file doesn't exist
      if ((error as NodeJS.ErrnoException).code !== 'ENOENT') {
        throw error;
      }
    }
  }
  
  /**
   * Clear all items from the cache
   */
  async clear(): Promise<void> {
    const files = await fs.readdir(this.cachePath);
    
    for (const file of files) {
      await fs.unlink(path.join(this.cachePath, file));
    }
  }
  
  /**
   * Get statistics about the cache
   * @returns Cache statistics
   */
  async getStats(): Promise<CacheStats> {
    const files = await fs.readdir(this.cachePath);
    let totalSize = 0;
    let oldestTimestamp = Date.now();
    let newestTimestamp = 0;
    
    for (const file of files) {
      const filePath = path.join(this.cachePath, file);
      const stats = await fs.stat(filePath);
      
      totalSize += stats.size;
      
      if (stats.mtime.getTime() < oldestTimestamp) {
        oldestTimestamp = stats.mtime.getTime();
      }
      
      if (stats.mtime.getTime() > newestTimestamp) {
        newestTimestamp = stats.mtime.getTime();
      }
    }
    
    return {
      itemCount: files.length,
      totalSize,
      oldestItem: new Date(oldestTimestamp),
      newestItem: new Date(newestTimestamp)
    };
  }
  
  /**
   * Check if an item exists in the cache
   * @param key Cache key
   * @returns True if the item exists and is not expired
   */
  async has(key: string): Promise<boolean> {
    return (await this.get(key)) !== null;
  }
  
  /**
   * Get all keys in the cache
   * @returns Array of cache keys
   */
  async getAllKeys(): Promise<string[]> {
    const files = await fs.readdir(this.cachePath);
    return files.map(file => path.basename(file, '.json'));
  }
  
  /**
   * Get or set cache item (convenience method)
   * @param key Cache key
   * @param factory Function to create the data if not cached
   * @param ttl Optional time-to-live in milliseconds
   * @returns Cached or newly created data
   */
  async getOrSet<T>(
    key: string,
    factory: () => Promise<T>,
    ttl: number | null = null
  ): Promise<T> {
    // Try to get from cache first
    const cachedData = await this.get<T>(key);
    if (cachedData !== null) {
      return cachedData;
    }
    
    // Create new data
    const newData = await profiler.measureAsync(
      `cache-miss:${key}`,
      factory
    );
    
    // Store in cache
    await this.set(key, newData, ttl);
    
    return newData;
  }
  
  /**
   * Get the file path for a cache key
   * @param key Cache key
   * @returns File path
   */
  private getCacheFilePath(key: string): string {
    // Sanitize key to be safe for filenames
    const safeKey = key.replace(/[^a-z0-9]/gi, '_');
    return path.join(this.cachePath, `${safeKey}.json`);
  }
}
```

### 10. Implement Configuration Optimizer
```typescript
// src/services/configurationOptimizer.ts
import { ConfigurationManager } from './configurationManager';
import { CacheManager } from './cacheManager';
import { profiler } from './profiler';

// Type for optimized configuration with index tables
interface OptimizedConfiguration {
  _optimized: boolean;
  _indexes?: {
    [indexName: string]: Record<string, any>;
  };
  [key: string]: any;
}

type ConfigChangeHandler = () => void;

/**
 * Optimizes configuration loading and access patterns
 */
export class ConfigurationOptimizer {
  private changeHandlers: ConfigChangeHandler[] = [];
  private configCacheTTL = 3600000; // 1 hour in milliseconds
  
  constructor(
    private configManager: ConfigurationManager,
    private cacheManager: CacheManager
  ) {
    // Subscribe to configuration changes
    this.configManager.subscribeToChanges(() => {
      this.handleConfigurationChanged();
    });
  }
  
  /**
   * Get optimized configuration
   * @returns Promise resolving to optimized configuration
   */
  async getOptimizedConfiguration(): Promise<OptimizedConfiguration> {
    // Get hash of the current configuration
    const configHash = await this.configManager.getConfigHash();
    
    // Try to get from cache
    const cachedConfig = await this.cacheManager.get<OptimizedConfiguration>(configHash);
    if (cachedConfig) {
      return cachedConfig;
    }
    
    // Load and optimize configuration
    const config = await profiler.measureAsync('optimize-config', async () => {
      const rawConfig = await this.configManager.getConfiguration();
      const optimizedConfig = this.optimizeConfiguration(rawConfig);
      
      // Cache the optimized configuration
      await this.cacheManager.set(
        configHash,
        optimizedConfig,
        this.configCacheTTL
      );
      
      return optimizedConfig;
    });
    
    return config;
  }
  
  /**
   * Invalidate configuration cache
   */
  async invalidateCache(): Promise<void> {
    const configHash = await this.configManager.getConfigHash();
    await this.cacheManager.delete(configHash);
  }
  
  /**
   * Subscribe to configuration changes
   * @param handler Function to call when configuration changes
   * @returns Unsubscribe function
   */
  onConfigurationChanged(handler: ConfigChangeHandler): () => void {
    this.changeHandlers.push(handler);
    
    // Return unsubscribe function
    return () => {
      const index = this.changeHandlers.indexOf(handler);
      if (index !== -1) {
        this.changeHandlers.splice(index, 1);
      }
    };
  }
  
  /**
   * Handle configuration changes
   */
  private async handleConfigurationChanged(): Promise<void> {
    // Invalidate cache
    await this.invalidateCache();
    
    // Notify all handlers
    for (const handler of this.changeHandlers) {
      handler();
    }
  }
  
  /**
   * Optimize configuration for faster access
   * @param config Original configuration
   * @returns Optimized configuration
   */
  private optimizeConfiguration(config: any): OptimizedConfiguration {
    const optimized: OptimizedConfiguration = {
      ...config,
      _optimized: true,
      _indexes: {}
    };
    
    // Create index tables for faster lookups
    
    // Index templates by ID if present
    if (Array.isArray(config.templates)) {
      optimized._indexes.templateById = {};
      for (const template of config.templates) {
        if (template.id) {
          optimized._indexes.templateById[template.id] = template;
        }
      }
    }
    
    // Index patterns by ID if present
    if (Array.isArray(config.patterns)) {
      optimized._indexes.patternById = {};
      for (const pattern of config.patterns) {
        if (pattern.id) {
          optimized._indexes.patternById[pattern.id] = pattern;
        }
      }
    }
    
    // Pre-compile regular expressions for patterns
    if (Array.isArray(config.patterns)) {
      optimized._indexes.compiledPatterns = {};
      for (const pattern of config.patterns) {
        if (pattern.regex) {
          try {
            optimized._indexes.compiledPatterns[pattern.id] = new RegExp(pattern.regex);
          } catch (error) {
            console.warn(`Failed to compile regex for pattern ${pattern.id}:`, error);
          }
        }
      }
    }
    
    // Create a flattened view of settings for faster access
    if (config.settings) {
      optimized._indexes.flatSettings = this.flattenObject(config.settings);
    }
    
    return optimized;
  }
  
  /**
   * Flatten a nested object into dot notation
   * @param obj Object to flatten
   * @param prefix Prefix for keys
   * @returns Flattened object
   */
  private flattenObject(obj: any, prefix: string = ''): Record<string, any> {
    const flattened: Record<string, any> = {};
    
    for (const [key, value] of Object.entries(obj)) {
      const newKey = prefix ? `${prefix}.${key}` : key;
      
      if (typeof value === 'object' && value !== null && !Array.isArray(value)) {
        // Recursively flatten nested objects
        Object.assign(flattened, this.flattenObject(value, newKey));
      } else {
        // Add leaf value
        flattened[newKey] = value;
      }
    }
    
    return flattened;
  }
}
```

### 11. Implement Startup Performance Optimization
```typescript
// src/app.ts
import { profiler } from './services/profiler';
import { ResourceManager } from './services/resourceManager';
import { CacheManager } from './services/cacheManager';
import { ConfigurationOptimizer } from './services/configurationOptimizer';
import { BackgroundWorker } from './services/backgroundWorker';
import { ConfigurationManager } from './services/configurationManager';
import { GitRepositoryDetector } from './services/gitRepositoryDetector';
import { GitOperationsService } from './services/gitOperations';
import * as path from 'path';

// Global resources
export const resourceManager = new ResourceManager();
export const backgroundWorker = new BackgroundWorker();

/**
 * Initialize the application with performance optimizations
 */
export async function initializeApp(): Promise<void> {
  profiler.mark('app-init-start');
  
  // Initialize cache manager
  const cacheDir = path.join(process.env.HOME || process.env.USERPROFILE || '.', '.zen-commit', 'cache');
  const cacheManager = new CacheManager(cacheDir);
  await cacheManager.initialize();
  
  // Register essential resources
  registerResources(cacheManager);
  
  // Start Git repository detection in the background
  backgroundWorker.execute('detect-repository', async () => {
    const gitDetector = await resourceManager.get<GitRepositoryDetector>('gitDetector');
    return gitDetector.detectRepository();
  });
  
  // Pre-load critical resources
  await resourceManager.preload(['configManager']);
  
  profiler.mark('app-init-end');
  
  // Log initialization performance
  const initTime = profiler.getDurationBetweenMarks('app-init-start', 'app-init-end');
  console.debug(`App initialized in ${initTime}ms`);
}

/**
 * Register application resources with the resource manager
 */
function registerResources(cacheManager: CacheManager): void {
  // Configuration management
  resourceManager.register('configManager', async () => {
    return new ConfigurationManager();
  });
  
  // Optimized configuration access
  resourceManager.register('configOptimizer', async () => {
    const configManager = await resourceManager.get<ConfigurationManager>('configManager');
    return new ConfigurationOptimizer(configManager, cacheManager);
  });
  
  // Git repository detection
  resourceManager.register('gitDetector', async () => {
    return new GitRepositoryDetector();
  });
  
  // Git operations
  resourceManager.register('gitOperations', async () => {
    const gitDetector = await resourceManager.get<GitRepositoryDetector>('gitDetector');
    const repoPath = await gitDetector.detectRepository();
    
    if (!repoPath) {
      throw new Error('Not in a Git repository');
    }
    
    return new GitOperationsService(repoPath);
  });
  
  // Register more resources...
}
```

### 12. Create Factory for Optimized Services
```typescript
// src/factories/performanceFactory.ts
import { profiler } from '../services/profiler';
import { resourceManager } from '../app';
import { BackgroundWorker } from '../services/backgroundWorker';
import { CacheManager } from '../services/cacheManager';
import { ConfigurationOptimizer } from '../services/configurationOptimizer';
import { ConfigurationManager } from '../services/configurationManager';
import * as path from 'path';

/**
 * Creates a profiler instance
 */
export function createProfiler(): typeof profiler {
  return profiler;
}

/**
 * Creates a background worker instance
 */
export function createBackgroundWorker(): BackgroundWorker {
  return new BackgroundWorker();
}

/**
 * Creates a cache manager instance
 */
export function createCacheManager(): CacheManager {
  const cacheDir = path.join(process.env.HOME || process.env.USERPROFILE || '.', '.zen-commit', 'cache');
  const cacheManager = new CacheManager(cacheDir);
  
  // Initialize asynchronously
  cacheManager.initialize().catch(error => {
    console.error('Failed to initialize cache manager:', error);
  });
  
  return cacheManager;
}

/**
 * Gets a resource from the resource manager
 */
export async function getResource<T>(name: string): Promise<T> {
  return resourceManager.get<T>(name);
}

/**
 * Creates a configuration optimizer instance
 */
export async function createConfigurationOptimizer(): Promise<ConfigurationOptimizer> {
  const configManager = await getResource<ConfigurationManager>('configManager');
  const cacheManager = createCacheManager();
  
  return new ConfigurationOptimizer(configManager, cacheManager);
}
```

### 13. Update Main CLI Entry Point with Performance Monitoring
```typescript
// src/cli.ts
import { initializeApp } from './app';
import { profiler } from './services/profiler';
import { createCommitCommand } from './commands/commit';
import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';

/**
 * Main CLI entry point
 */
async function main(): Promise<void> {
  profiler.mark('cli-start');
  
  // Initialize app (with optimized loading)
  await initializeApp();
  
  // Define CLI commands
  const cli = yargs(hideBin(process.argv))
    .scriptName('zen-commit')
    .usage('$0 <command> [options]')
    .option('verbose', {
      alias: 'v',
      type: 'boolean',
      description: 'Run with verbose logging'
    })
    .option('profile', {
      type: 'boolean',
      description: 'Show performance profiling information'
    });
  
  // Register commands
  cli.command(createCommitCommand());
  
  // Handle --profile flag
  if (cli.argv.profile) {
    process.on('exit', () => {
      profiler.mark('cli-end');
      console.log(profiler.getReport());
    });
  }
  
  // Parse arguments and execute command
  await cli.parse();
  
  profiler.mark('cli-end');
  
  // Log total execution time (in verbose mode)
  if (cli.argv.verbose) {
    const totalTime = profiler.getDurationBetweenMarks('cli-start', 'cli-end');
    console.log(`Execution completed in ${totalTime}ms`);
  }
}

// Run the CLI
main().catch(error => {
  console.error('Error:', error);
  process.exit(1);
});
```

## Definition of Done
- The application startup time is significantly improved
- Resources are loaded lazily when needed
- Performance is measured and optimized
- Caching is implemented for expensive operations
- Configuration loading is optimized
- Background processing is available for non-critical operations
- All test cases pass and achieve adequate coverage

## Potential Blockers
- Balancing startup performance with feature functionality
- Maintaining accurate profiling across different environments
- Ensuring cache invalidation works correctly
- Handling race conditions in parallel operations

## Next Steps
- Large Repository Handling (4.3.2)
- Memory Usage Optimizations (4.3.3)